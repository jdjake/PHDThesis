%!TEX root = ../main.tex

In this chapter, we prove Theorem \ref{maintheorem}, which we restate below:

\thmmaintheorem*

In Section \ref{sec:AnAnalogueOf} we saw that for operators $P$ satisfying Assumption A, $\| a \|_{M^p_{\text{Dil}}(X)} \gtrsim \| a \|_{R^{s,p}[0,\infty)}$, and so it suffices to prove that $\| a \|_{M^p_{\text{Dil}}(X)} \lesssim \| a \|_{R^{s,p}[0,\infty)}$. Define $a_R(\lambda) = a(\lambda / R)$. In Section \ref{PrelimSetup}, we will see from elementary functional analysis that
%
\begin{equation} \label{TrivialLowFrequencyBound}
    \sup\nolimits_{R \leq 1} \left\| a_R \right\|_{M^p(X)} \lesssim \| a \|_{l^\infty[0,\infty)} \lesssim \| a \|_{R^{s,p}[0,\infty)}.
\end{equation}
%
On the other hand, the upper bound
%
\begin{equation} \label{dyadicMainReulst}
    \sup\nolimits_{R \geq 1} \| a_R \|_{M^p(X)} \lesssim \| a \|_{R^{s,p}[0,\infty)}.
\end{equation}
%
requires a more in depth analysis than \eqref{TrivialLowFrequencyBound}. It is here we apply the wave equation transform, writing
%
\begin{equation}
    a_R(P) = \int_{-\infty}^\infty R\;\! \widehat{a}(Rt) e^{2 \pi i t P}\; dt,
\end{equation}
%
which reduces $a_R(P)$ to studying averages associated with solutions to the half-wave equation $\partial_t = 2 \pi i P$ on $X$. We obtain \eqref{dyadicMainReulst} by studying averages to the wave equation using several methods, including:
%
\begin{itemize}
    \item[(A)] Quasi-orthogonality estimates for averages of solutions to the half-wave equation on $X$, discussed in Section \ref{estimatesforwavepackets}, which arise from a study of the geometry of the Finsler metric on $X$.

    \item[(B)] Variants of the density-decomposition arguments, which we introduced in Section \ref{sec:densitydecompositions}, to control the `small time behavior' of solutions to the half-wave equation. We carry out these arguments in section \ref{regime1firstsection}

    \item[(C)] A new strategy to reduce the `large time behavior' of the half-wave equation to an endpoint local smoothing inequality for the half-wave equation on $X$, described in Section \ref{regime2finalsection}.
\end{itemize}
%
Equations \eqref{TrivialLowFrequencyBound} and \eqref{dyadicMainReulst} thus imply Theorem \ref{maintheorem}.

\section{Preliminary Setup} \label{PrelimSetup}

Without loss of generality, by translating and dilating our multiplier, we can assume that the eigenvalues of the operator $P$ are all integers. Fix a constant $\varepsilon_X > 0$, strictly smaller than the injectivity radius of the geodesic flow on the manifold $X$ induced by the geometry of $P$. Our goal is to prove inequalities \eqref{TrivialLowFrequencyBound} and \eqref{dyadicMainReulst}. Proving \eqref{TrivialLowFrequencyBound} is simple because the operators $a_R(P)$ are smoothing operators, uniformly for $0 < R < 1$, because the spectrum of $X$ is discrete, low eigenvalue eigenfunctions are uniformly smooth, and $X$ is compact.

\begin{lemma} \label{lowjLemma}
    Let $X$ be a compact $d$-dimensional manifold, and suppose $P \in \COP{1}(X)$. If $1/2d < 1/p - 1/2 \leq 1/2$, and if $a$ is a regulated function, then
    %
    \[ \sup\nolimits_{R \leq 1} \| a_R \|_{M^p_{\text{Dil}}(X)} \lesssim \| a \|_{l^\infty(\Lambda)} \lesssim \| a \|_{R^{p,s}[0,\infty)}. \]
\end{lemma}
\begin{proof}
    Let $T_R = m_R(P)$. Recall that $\Lambda$ is the set of eigenvalues of $P$. The set $\Lambda \cap [0,2]$ is finite. For each $\lambda \in \Lambda$, choose a finite orthonormal basis $\mathcal{E}_\lambda$. Then we can write
    %
    \begin{equation}
        T_R = \sum\nolimits_{\lambda \in \Lambda} \sum\nolimits_{e \in \mathcal{E}_\lambda} \langle f, e \rangle e.
    \end{equation}
    %
    Since $\mathcal{V}_\lambda \subset C^\infty(X)$, H\"{o}lder's inequality implies
    %
    \begin{equation}
    \begin{split}
        \| \langle f, e \rangle e \|_{L^p(X)} &\leq \| f \|_{L^p(X)} \| e \|_{L^{p'}(X)} \| e \|_{L^p(X)} \lesssim_\lambda \| f \|_{L^p(X)}.
    \end{split}
    \end{equation}
    %
    But this means that
    %
    \begin{equation}
        \left\| T_R f \right\|_{L^p(X)} \leq \sum\nolimits_{\lambda \in \Lambda_P \cap [0,2]} \sum\nolimits_{e \in \mathcal{E}_\lambda} |m(\lambda/R)| \| \langle f, e \rangle e \|_{L^p(X)} \lesssim \| m \|_{l^\infty(\Lambda)}.
    \end{equation}
    %
    For $1/p - 1/2 > 1/2d$, the Sobolev embedding theorem and \eqref{equation12980u21u89eqiwjqwiou} imply that
    %
    \begin{equation}
        \| a \|_{l^\infty(\Lambda)} \lesssim \| a \|_{W^{s,p'}[0,\infty)} \lesssim \| a \|_{R^{s,p}[0,\infty)},
    \end{equation}
    %
    which completes the proof.
\end{proof}

We now begin to reduce the analysis of $a_R(P)$ for $R \geq 1$ to the study of the wave equation. Fix a bump function $q \in C_c^\infty(\RR)$ with $\supp(q) \subset [1/4,4]$ and $q(\lambda) = 1$ for $\lambda \in [1/2,2]$, and define $Q_R = q(P/R)$. % has range contained in the finite dimensional subspace $V_R$ of $C^\infty(M)$ spanned by eigenfunctions of $P$ with eigenvalues in $[2^{j-2},2^{j+2}]$. Since $P$ is elliptic, it is often a useful heuristic that elements of $V_R$ are `frequency localized' at a scale $R$.
We write
%
\begin{equation}
    T_R = T_R \circ Q_R = \int_{\RR} R\;\! \widehat{m}(R t) (e^{2 \pi i t P} \circ Q_R)\; dt,
\end{equation}
%
and view the operators $(e^{2 \pi i t P} \circ Q_R)$ as `frequency localized' wave propagators.

Because all eigenvalues of $P$ are integers, it follows that $e^{2 \pi i (t + n) P} = e^{2 \pi i t P}$ for any $t \in \RR$ and $n \in \ZZ$. Let $I_0$ denote the interval $[-1/2,1/2]$. We may then write
%
\begin{equation}
    T_R = \int_{I_0} b_R(t) (e^{2 \pi i tP} \circ Q_R)\; dt,
\end{equation}
%
where $b_R: I_0 \to \CC$ is the periodic function
%
\begin{equation}
    b_R(t) = \sum\nolimits_{n \in \ZZ} R \widehat{m}(R (t + n)).
\end{equation}
% Sphere 1, but we scale is by 1/2pi
% Sphere of radius 1/2 pi, has sectional curvatures kappa = 2 pi
% so 1/4
We split our analysis of $T_R$ into two regimes: regime $\text{I}$ and regime $\text{II}$. In regime $\text{I}$, we analyze the behaviour of the wave equation over times $0 \leq |t| \leq \varepsilon_X$ by decomposing this time interval into length $1/R$ pieces, and analyzing the interactions of the wave equations between the different intervals. In regime $\text{II}$, we analyze the behaviour of the wave equation over times $\varepsilon_X \leq |t| \leq 1$. Here we need not perform such a decomposition, since the $R^{s,p}$ norm gives better control on the function $b_R$ over these times.
%Heuristically, the result is just a discretization of the condition that $C_p(m) < \infty$, but using the additional fact that $b_j$ was obtained from a periodization of the Fourier transform of a function with `frequency support' on an annulus of radius $2^j$, and thus locally constant at a scale $1/2^j$. This allows us to replace $L^p$ norms with $L^1$ norms on intervals of length $1/2^j$ without incurring any loss.

\begin{lemma} \label{decompositionLemma}
    Fix $\varepsilon > 0$. Let $\mathcal{T}_R = \ZZ/R \cap [-\varepsilon, \varepsilon]$ and define $I_t = [t - 1/R, t + 1/R]$. For any function $a: [0,\infty) \to \CC$, define a periodic function $b: I_0 \to \CC$ by setting
    %
    \[ b(t) = \sum\nolimits_{n \in \ZZ} R \widehat{m}(R(t + n)). \]
    %
    Then we can write $b = \left( \sum\nolimits_{t_0 \in \mathcal{T}_R} b_{t_0}^I \right) + b^{II}$, where
    %
    \[ \supp(b_{t_0}^I) \subset I_{t_0} \quad\text{and}\quad \supp(b_R^{II}) \subset I_0 \smallsetminus [-\varepsilon,\varepsilon]. \]
    %
    Moreover, we have
    %
    \[ \left( \sum\nolimits_{t_0 \in \mathcal{T}_R} \Big[ \| b^I_{t_0} \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \Big]^p \right)^{1/p} \lesssim R^{1/p'} \| a \|_{R^{s,p}[0,\infty)} \]
        %
        and
        %
    \[ \| b^{II} \|_{L^p(I_0)} \lesssim R^{1/p' - (d-1)(1/p - 1/2)} \| a \|_{R^{s,p}[0,\infty)}. \]
\end{lemma}
\begin{proof} [Proof of Lemma \ref{decompositionLemma}]
    The intervals $\{ I_{t_0} : t_0 \in \mathcal{T}_R \}$ cover $[-\varepsilon,\varepsilon]$, and so we may consider an associated partition $\mathbb{I}_{[-\varepsilon,\varepsilon]} = \sum_{t_0} \chi_{t_0}$ where $\text{supp}(\chi_{t_0}) \subset I_{t_0}$ and $|\chi_{t_0}| \leq 1$. Define $b_{t_0}^I = \chi_{t_0} b_j$ and $b^{II} = (1 - \mathbb{I}_{[-\varepsilon,\varepsilon]} ) b$. Then $b = \sum_{t_0} b_{t_0}^I + b^{II}$, and the support assumptions are satisfied. It remains to prove the required norm bounds for these choices. For each $n \in \ZZ$, define a function $b_{n}: I_0 \to \CC$ by setting $b_{n}(t) = R \widehat{m}(R (t + n))$. Then $b = \sum_n b_{n}$. Moreover,
    %
    \begin{align} \label{translationlpcalculation}
    \begin{split}
        &\left( \sum_{n \neq 0} \left[ \langle R n \rangle^{s} \| b_{n} \|_{L^p(I_0)} \right]^p \right)^{1/p}\\
        %&\quad\quad\quad \sim \left( \int_{-1/2}^{1/2} \sum_{n \neq 0} \left[ \langle R(t + n) \rangle^{s} |R \widehat{m}(R ( t + n ))| \right]^p\; dt \right)^{1/p}\\
        &\quad\quad\quad \sim \left( \int_{|t| \geq 1/2} \left[ \langle R t \rangle^{s} |R \widehat{m}(R t)| \right]^p \right)^{1/p}\\
        &\quad\quad\quad = R^{1/p'} \left( \int_{|t| \geq R/2} \left[ |t|^{s} \widehat{m}(t) \right]^p \right)^{1/p} \leq R^{1/p'} C_p(m).
    \end{split}
    \end{align}
    %
    Write $b_{t_0}^I = \sum_n b_{t_0,n}^I$ and $b^{II} = \sum_n b_{n}^{II}$, where $b_{t_0,n}^I = \chi_{t_0} b_n$ and $b_n^{II} = \mathbb{I}_{I_0 \smallsetminus [-\varepsilon, \varepsilon] } b_{n}$. Then
    %
    \begin{align} \label{zerobj0iicalculation}
    \begin{split}
        \| b_{0}^{II} \|_{L^p(I_0)} &= \left( \int_{\varepsilon \leq |t| \leq 1/2} |R \widehat{m}(R t)|^p \right)^{1/p}\\
        &= R^{1/p'} \left( \int_{R \varepsilon \leq |t| \leq R/2} |\widehat{m}(t)|^p \right)^{1/p} \lesssim R^{1/p' - s} C_p(m).
    \end{split}
    \end{align}
    %
    Using \eqref{translationlpcalculation}, \eqref{zerobj0iicalculation}, and H\"{o}lder's inequality, we conclude that
    %
    \begin{align}
    \begin{split}
        \|  b^{II} \|_{L^p(I_0)} &\leq \sum\nolimits_n \| b_{n}^{II} \|_{L^p(I_0)}\\
        &\leq \| b_{0}^{II} \|_{L^p(I_0)} + \sum\nolimits_{n \neq 0} \left[ |R n|^{s} \| b_{n}^{II} \|_{L^p(I_0)} \right] \frac{1}{|R n|^{s}}\\
        &\leq \| b_{0}^{II} \|_{L^p(I_0)} + R^{-s} \left( \sum\nolimits_{n \neq 0} \left[ |R n|^{s} \| b_{n} \|_{L^p(I_0)} \right]^p \right)^{1/p}\\ % \left( \sum_{n \neq 0} \frac{1}{|R n |^{s p'}} \right)^{1/p'}\\
        &\lesssim R^{1/p' - s} C_p(m).
    \end{split}
    \end{align}
    %
    A similar calculation shows that
    %
    \begin{align} \label{eacht0bjcalculation}
    \begin{split}
        \| b_{t_0}^I \|_{L^p(I_0)} &\leq \sum\nolimits_n \| b_{t_0,n}^I \|_{L^p(I_0)}\\
        &= \| b_{t_0,0}^I \|_{L^p(I_0)} + \sum\nolimits_{n \neq 0} \| b_{t_0,n}^I \|_{L^p(I_0)}\\
        &\lesssim \| b_{t_0,0}^I \|_{L^p(I_0)} + R^{-s} \Big( \sum\nolimits_{n \neq 0} |R n|^{s} \| b_{t_0,n}^I \|_{L^p(I_0)}^p \Big)^{1/p}\\
        &\lesssim \| b_{t_0,0}^I \|_{L^p(I_0)} + \Big( \sum\nolimits_{n \neq 0} |R n|^{s} \| b_{t_0,n}^I \|_{L^p(I_0)}^p \Big)^{1/p}.
    \end{split}
    \end{align}
    %
    Using \eqref{eacht0bjcalculation}, we calculate that
    %
    \begin{align} \label{bjt0Icalculation}
    \begin{split}
        &\left( \sum_{t_0 \in \mathcal{T}_R} \left[ \| b_{t_0}^I \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \right]^p \right)^{1/p}\\
        &\quad\quad \lesssim \left( \sum_{t_0 \in \mathcal{T}_R} \left[ \| b_{t_0,0}^I \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \right]^p + \sum_{n \neq 0} \left[ |R n|^{s} \| b_{t_0,n}^I \|_{L^p(I_0)} \right]^p \right)^{1/p}\\
        &\quad\quad \lesssim \left( \int_{\RR} \left[ \langle R t \rangle^{s} R \widehat{m}(R t) \right]^p dt \right)^{1/p}\\
        &\quad\quad \lesssim R^{1/p'} C_p(m).
    \end{split}
    \end{align}
    %
    Since each function $b_{t_0}^I$ is supported on a length $1/R$ interval, we have
    %
    \begin{equation}
        \| b_{t_0}^I \|_{L^1(I_0)} \lesssim R^{-1/p'} \| b_{t_0}^I \|_{L^p(I_0)},
    \end{equation}
    %
    and substituting this inequality into \eqref{bjt0Icalculation} completes the proof.
\end{proof}

The following proposition, a kind of $L^p$ square root cancellation bound, implies \eqref{dyadicMainReulst} once we take Lemma \ref{decompositionLemma} into account. % and comparing \eqref{DKAPDKAWIODJAWOI} with \eqref{ejqwoifjeoifjwqoifjwqoi} and \eqref{DWAIOJDAOIWDJWAIODJIOJD} with \eqref{DPOIJAOIWDJQWIOFJQOIVJIEOVNFNJNVNV},
Since we already proved \eqref{TrivialLowFrequencyBound}, this proposition completes the proof of Theorem \ref{maintheorem}, and will take the remainder of the chapter.

\begin{prop} \label{TjbLemma}
    Let $X$ be a $d$-dimensional compact manifold, and consider $P \in \COP{1}(X)$ satisfying Assumptions A and B. Fix $R > 0$ and a constant $\varepsilon_X$ smaller than the injectivity radius of $X$ with respect to the geodesic flow induced by $P$, and suppose $1/(d-1) < 1/p - 1/2 < 1/2$. Consider any function $b: I_0 \to \CC$, and suppose we can write $b = \sum\nolimits_{t_0 \in \mathcal{T}_R} b_{t_0}^I + b^{II}$, where $\supp(b_{t_0}^I) \subset I_{t_0}$ and $\supp(b_R^{II}) \subset I_0 \smallsetminus [-\varepsilon_X,\varepsilon_X]$. Define operators $T^I = \sum\nolimits_{t_0 \in \mathcal{T}_R} T^I_{t_0}$ and $T^{II}$, where
    %
    \[ T_{t_0}^I = \int b_{t_0}^I(t) ( e^{2 \pi i tP} \circ Q_R )\; dt\ \ \text{and}\ \ T^{II} = \int b^{II}(t) ( e^{2 \pi i tP} \circ Q_R)\; dt. \]
    %
    Then if $s = (d-1)(1/p - 1/2)$, then
    %
    \begin{equation} \label{ejqwoifjeoifjwqoifjwqoi}
        \| T^I \|_{L^p \to L^p} \lesssim R^{-1/p'} \left( \sum\nolimits_{t_0 \in \mathcal{T}_R} \Big[ \| b^I_{t_0} \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \Big]^{p} \right)^{1/p}
    \end{equation}
    %
    and
    %
    \begin{equation} \label{DPOIJAOIWDJQWIOFJQOIVJIEOVNFNJNVNV}
        \| T^{II} \|_{L^p \to L^p} \lesssim R^{s - 1/p'} \| b^{II} \|_{L^p(I_0)}.
    \end{equation}
\end{prop}

\begin{remark}
    One should view this proposition as a discretization of Theorem \ref{maintheorem}, and thus compared to Lemma \ref{lemma2} in the argument of Heo, Nazarov, and Seeger.
\end{remark}

Proposition \ref{TjbLemma} splits the main bound of the paper into two regimes: regime $\text{I}$ and regime $\text{II}$. Noting that we require weaker bounds in \eqref{DPOIJAOIWDJQWIOFJQOIVJIEOVNFNJNVNV} than in \eqref{ejqwoifjeoifjwqoifjwqoi}, the operator $T^{II}$ will not require as refined an analysis as for the operator $T^I$, and we obtain bounds on $T^{II}$ by a reduction to an endpoint local smoothing inequality in Section \ref{regime2finalsection}. On the other hand, to obtain more refined estimates for the $L^p$ norms of quantities of the form $f = T^I u$, we consider a decompositions of the form $u = \sum_{x_0} u_{x_0}$, where $u_{x_0}: X \to \CC$ is supported on a ball $B(x,1/R)$ of radius $1/R$ centered at $x_0$. We then have $\smash{f = \sum\nolimits_{(x_0,t_0)} f_{x_0,t_0}}$, where $f_{x_0,t_0} = T^I_{t_0} u_{x_0}$. To control $f$ we must establish an $L^p$ square root cancellation bound for the functions $\{ f_{x_0,t_0} \}$. In the next section, we study the $L^2$ quasi-orthogonality of these functions, which we use as a starting point to obtain the required square root cancellation.

% Finsler geometry arises in our problem because the principal symbol $p: T^* M \to [0,\infty)$ acts as a Minkowski norm on the cotangent spaces $T^* M$%, and thus induces a Finsler metric on $M$ by taking the dual Minkowski norm. % $F(x,v) = \sup\nolimits_{\xi \in S\!_x^*} \xi(v)$. % A very similar theory of geodesics and curvature can be developed for Finsler manifolds as for Riemannian manifolds. The main difference is that a geodesic travelling from one point $p$ to another point $q$ need not be a geodesic when the orientation of the geodesic is reversed. Thus the induced distance function $d_+$ on a Finsler manifold \emph{need not be symmetric}.

% given a homogeneous function $F: TM \to [0,\infty)$ which induces a smoothly varying \emph{Minkowski norm} on the tangent spaces of $M$. 

%A similar theory of geodesics and curvature can be developed for Finsler manifolds, and the geodesic flow on $T^* M$ induced by the Finsler metric $M$ is precisely the Hamiltonian flow induced by the function $p$. The most important difference arising in our calculations between Riemannian and Finsler geometry is that the shortest geodesic travelling from a point $x_0 \in M$ to a point $x_1 \in M$ need not agree with the shortest geodesic travelling from $x_1$ to $x_0$; we call the former a \emph{forward geodesic} from $x_0$ to $x_1$, and the latter a \emph{backward geodesic} for $x_0$ to $x_1$, and denote the lengths of these geodesics by $d_+(x_0,x_1)$ and $d_-(x_0,x_1)$ respectively; the functions $d_+$ and $d_-$ obey the triangle inequality, but are \emph{not symmetric}. We make no assumption that the reader of this paper is familiar with Finsler geometry in this paper, describing the necessary results we need, and giving explicit citations for those who wish to know more details. 

\begin{comment}

Other than this theory, the only non-standard topic in Finsler geometry we will use is a theory of \emph{approximations to normal coordinates}. In Finsler geometry, for each $x \in M$ we can use geodesics to define a diffeomorphism of a neighborhood of the origin in $T_x M$ into $M$. This map will be smooth away from the origin. However, unlike in Riemannian geometry, normal coordinates on a Finsler manifold are in general only $C^1$ at the origin, which can cause issues. Fortunately in our argument we will only need to consider an approximate normal coordinate system which is $C^\infty$, based on a method of Douglas and Thomas \cite{Douglas,Thomas}. One can find a more modern exposition and extension of the method in \cite{Pfeifer}. For each $(x,v) \in TM - 0$, and each $y \in T_p M$, we consider the system of ordinary differential equations
%
\begin{align*}
    \frac{d^2 c^i}{dt^2} = - \sum\nolimits_{a,b} \gamma^i_{ab}(c,s) \dot{c}^a \dot{c}^b \quad\text{and}\quad \dot{s} = - \sum\nolimits_{a,b} \gamma^i_{ab}(c,s) \dot{c}^a s^b,
\end{align*}
%
where $c(0) = x$, $\dot{c}(0) = y$, and $s(0) = v$. If $y$ is suitably close to the origin, we can guarantee that $c$ and $s$ exist on $[0,1]$ with $s(t) \neq 0$ for all $t \in [0,1]$. Thus the coefficients of the ordinary differential equation are \emph{smooth} on a neighbourhood of the trajectories of $c$ and $s$, which gives us \emph{smooth dependence on the initial data}. By compactness, in some pre-compact coordinate system $(x,U)$, we can find an open ball $B \subset \RR^d$ such that for all $x \in U$, all $w \in B$, and all $v \in T_x M$ with $F(x,v) = 1$, the property above is true. But if $SM = \{ (x,v) \in TM : F(x,v) = 1 \}$ denotes the sphere bundle, this means we can find an open precompact set $U \subset SM \otimes TM$ containing $SM \times 0$ and a smooth map $F: U \to M$ such that for each $(x,v) \in SM$, $F(x,v,\cdot)$ is a $C^\infty$ diffeomorphism. The inverse is thus a coordinate system $y_{x,v}$. It has the property that the geodesic starting at $x$ with tangent vector will be mapped to a straight line in the coordinate system, but not necessarily the other geodesics starting at $x$. Thus in this coordinate system $G(0,v) = 0$.
% N^a_b(0,v)
% Thus
% 0 = - \sum\nolimits_{a,b} \gamma^i_{ab}(tv,v) v^a v^b \quad\text{for $1 \leq i \leq d$},

we can find $B_x \subset T_x M$ such that this is true for all $y \in B_x$ and $v$ with $F(x,v) = 1$, and in coordinates, the. But this implies that the coefficients of the ordinary differential equations have \emph{smooth coefficients}, and so we get smooth initial dependence on the data. Choosing an open precompact set $U \subset \bigcup_x \{ x \} \times B_x \times S\!_x$, we get a smooth map $F: U \to M$ which restricts to a diffeomorphism $F_{x,v}: B_x$ for each $x \in M$ and $v \in T_x M$ with $F(x,v) = 1$.

A proof of these facts using more modern notation is given in Theorem 7 of \cite{Pfeifer}.

\end{comment}

\section{Quasi-Orthogonality Estimates For Wave-Packets} \label{estimatesforwavepackets}

The discussion at the end of Section \ref{PrelimSetup} motivates us to consider estimates for functions obtained by taking averages of the wave equation over a small time interval, with initial conditions localized to a particular part of space. In this section, we study the $L^2$ orthogonality of such quantities. One should compare the results of this section to the results of Lemma \ref{lemma4}. We do not exploit periodicity of the Hamiltonian flow in this section since we are only dealing with estimates for the half wave-equation for \emph{small times}. Our results here thus hold for any manifold $X$, and any operator $P$ whose principal symbol has cospheres with non-vanishing Gaussian curvature. In order to prove the required quasi-orthogonality estimates of the functions $\{ f_{x_0,t_0} \}$, we find a new connection between the Finsler geometry we introduced in section \ref{sec:geometriesinduced} and the behaviour of the operator $P$. In particular, recall the quasimetrics $d_+$ and $d_-$ introduced in that section.

\begin{prop} \label{theMainEstimatesForWave}
    Let $X$ be a compact manifold of dimension $d$, and suppose $P \in \COP{1}(X)$ satisfies the curvature assumptions of Theorem \ref{maintheorem}. Suppose $\varepsilon_X > 0$ is chosen smaller thant he injectivity radius of $X$. Then for all $R \geq 0$, the following estimates hold:
    %
    \begin{itemize}%[leftmargin=8mm]
        \item (Pointwise Estimates) Fix  $|t_0| \leq \varepsilon_X$ and $x_0 \in X$. Consider any two $L^1$ normalized functions $c: \RR \to \CC$ and $u: X \to \CC$ with $\supp(c) \subset I_{t_0}$ and $\supp(u) \subset B(x_0,1/R)$. Define $S\!_{x_0,t_0}: X \to \CC$ by setting
        %
        \[ S\!_{x_0,t_0} = \int c(t) (e^{2 \pi i t P} \circ Q_R) \{ u \}\; dt. \]
        %
        Then for any $K \geq 0$, and any $x \in X$,
        %
        \[ |S\!_{x_0,t_0}(x)| \lesssim_K \frac{R^d}{\langle R d_X(x_0,x) \rangle^{\frac{d-1}{2}}} \max\nolimits_{\pm} \Big\langle R \big| t_0 \pm d_X^\pm(x,x_0) \big| \Big\rangle^{-K}. \]

        \item (Quasi-Orthogonality Estimates) Fix $|t_0 - t_1| \leq \varepsilon_X$, and $x_0, x_1 \in X$. Consider $L^1$ normalized functions $c_0,c_1: \RR \to \CC$ and $u_0,u_1: X \to \CC$ such that, for each $\nu \in \{ 0, 1 \}$, $\supp(c_\nu) \subset I_{t_\nu}$ and $\supp(u_\nu) \subset B(x_\nu,1/R)$. Define $S\!_{x_\nu,t_\nu}: X \to \CC$ by setting
        %
        \[ S\!_{x_\nu,t_\nu} = \int c_\nu(t) (e^{2 \pi i t P} \circ Q_R) \{ u_\nu \}\; dt. \]
        %
        Then for any $K \geq 0$,
        %
        \[ \left| \langle S\!_{x_0,t_0}, S\!_{x_1,t_1} \rangle \right| \lesssim_K \frac{R^d}{\langle R d_X(x_0,x_1) \rangle^{\frac{d-1}{2}}} \max\nolimits_{\pm} \Big\langle R \big| (t_0 - t_1) \pm d^\pm(x_0,x_1) \big| \Big\rangle^{-K}. \]
    \end{itemize}
\end{prop}

%\begin{remark} The choice of balls $B(x_0,1/R)$ in the statement above is somewhat arbitrary. We assume we have fixed some choice of open sets $B(x,\delta)$ in $M$ for each $x \in M$ and $0 < \delta < 1$, such that for each coordinate chart $F: U \to \RR^d$ and each compact set $K \subset U$, there exists $C > 1$ such that for all $x \in K$ and $0 < \delta < 1$,
%%
%\begin{equation}
%    B(F(x), C^{-1} \delta) \subset F(B(x,\delta)) \subset B(F(x), C \delta),
%\end{equation}
%
%and where the balls in $\RR^d$ are the usual Euclidean balls. The particular choice given will only effect the magnitude of $\varepsilon_X$ and the implicit constants in the statement of the proposition. Fixing an arbitrary Riemannian metric on $M$ and then letting $B(x,\delta)$ be the resulting metric balls will suffice for our purposes.
%\end{remark}

%    \begin{figure}[h]
%        \centering
%        \includegraphics[width=0.3\textwidth]{TangenciesOnSphere.png}
%    \end{figure}

\begin{remark}
    Just as in Lemma \ref{lemma4}, the pointwise estimate of Lemma \ref{theMainEstimatesForWave} tells us that the function $S$ is concentrated on a geodesic annulus of radius $|t_0|$ centered at $x_0$ and thickness $O(1/R)$. %The annulus has thickness $O(1/R)$, and on this annulus the function $S$ has magnitude at most $O(R^{\frac{d+1}{2}} |t_0|^{- \frac{d-1}{2}})$.
The quasi-orthogonality estimate tells us that the two functions $S\!_{x_0,t_0}$ and $S\!_{x_1,t_1}$ are only significantly correlated with one another if the two annuli on which the majority of the support lies are internally or externally tangent to one another, depending on whether $t_0$ and $t_1$ have the same or opposite sign respectively. %, and then
%
%\begin{equation} \label{DIOAWJDOIWJAFOIJWAFcCw}
%    |\langle S\!_0, S\!_1 \rangle| \lesssim R^{\frac{d+1}{2}} |t_0 - t_1|^{- \frac{d-1}{2}}.
%\end{equation}
%
%, though the upper bounds here look superficially different, because here we are using the half wave equation to define our functions $\{ S\!_\nu \}$, whereas in \cite{HeoandNazarovandSeeger} the analogous functions are simply defined by taking smooth functions adapted to certain annuli. Normalizing and rescaling appropriately causes the bounds to match.
\end{remark}

%We denote the induced metric on $M$ by taking the lengths of forward geodesics between points by $d_X^+: M \times M \to [0,\infty)$, and the induced metric by taking the lengths of backward geodesics by $d_M^-: M \times M \to [0,\infty)$.

% Thus $S\!_x^*$ has everywhere positive scalar curvature by continuity.\footnote{This argument is a higher dimensional variant of the argument of Chapter 2, Theorem 4.2 of \cite{HeinzHopf}.} But then Hadamard's ovaloid theorem (see Chapter 4, Theorem 2.1 of \cite{HeinzHopf}) implies that for each $x \in M$, the interior of $S\!_x^*$ is strictly convex. Thus $p$ is a strictly convex function in the $\xi$ variable.

%For each $x \in M$, define $\| \cdot \|_x^2$ to be the Legendre transform of $p(x,\cdot)^2$. Then $\| \cdot \|$ is a smoothly varying family of strictly convex norms on $TM$, and thus gives a Finsler metric on $M$. Moreover, the geodesic flow with respect to this metric is precisely the Hamiltonian flow induced by the principal symbol $p$, since $p$ is precisely the dual Finsler metric on $T^* M$ to the Finsler metric $\| \cdot \|$ on $TM$. %(the usual process of taking the Legendre transform of the Euler-Lagrange equations defining geodesics is precisely the inverse of the procedure we have used to define the metric on $M$ from the function $p$).
%Slightly abusing notation, we will sometimes denote the principal symbol $p: T^* M \to [0,\infty)$ by $\| \cdot \|$, the distinction between the norm $\| \cdot \|$ being clear depending on whether it is applied to a tangent vector or covector. We denote the induced metric on $M$ by taking the lengths of forward geodesics between points by $d_M^+: M \times M \to [0,\infty)$, and the induced metric by taking the lengths of backward geodesics by $d_M^-: M \times M \to [0,\infty)$.

\begin{proof}[Proof of Proposition \ref{theMainEstimatesForWave}]

To simplify notation, in the following proof we will suppress the use of $R$ as an index, for instance, writing $Q$ for $Q_R$. For both the pointwise and quasi-orthogonality estimates, we want to consider the operators in coordinates, so we can use Theorem \ref{thm:equivalenceofphase} to understand the wave propagators in terms of various oscillatory integrals. Consider a small quantity $\varepsilon_X' < \varepsilon_X$, to be fixed later.

We begin with a proof of the pointwise bounds. Write $S = S\!_{x_0,t_0}$. Start by covering $X$ by a finite family of suitably small open sets $\{ V_\alpha \}$, such that for each $\alpha$, there is a coordinate chart $U_\alpha$ compactly containing $V_\alpha$ and with $N(V_\alpha, 1.1 \varepsilon_X) \subset U_\alpha$. Let $\{ \eta_\alpha \}$ be a partition of unity subordinate to $\{ V_\alpha \}$. Given $u: M \to \CC$, write $u = \sum_\alpha u_\alpha$, where $u_\alpha = \eta_\alpha u$.

Let us first address the case where $\varepsilon_X' \leq |t_0| \leq \varepsilon_X$. Lemmas \ref{PseudoOsicllatoryLemma} and \ref{lemma:WaveOscillatoryLemmaddw} imply that if we define
%
\begin{equation}
    S\!_\alpha = \int c(t) (Q_\alpha \circ W_\alpha(t) \circ Q_\alpha) \{ u_\alpha \}\; dt,
\end{equation}
%
where $Q_\alpha$ is a pseudo-differential operator whose symbol in the coordinate system $U_\alpha$ is supported on $\{ R/4 \leq |\xi| \leq 4R \}$, and
%
\[ W_\alpha(x,y) = R^{\frac{d+1}{2}} \int_{-\infty}^\infty s(t,x,y,R\tau) e^{i R \tau \Phi(x,t,x',\tau)}\; d\xi, \]
% t = d(x,y)
% 
% 
where $s$ is smooth, and compactly supported on $L^{-1} \leq |\tau| \leq L$, and $\Phi$ is defined in \eqref{onedwavephase}, then for all $N \geq 0$,
%
\begin{equation} \label{parametrixerrroestimate}
    \left\| S - \textstyle\sum\nolimits_\alpha S\!_\alpha \right\|_{L^\infty(X)} \lesssim_N R^{-N}.
\end{equation}
%
This error is negligible to our analysis if $N$ is chosen appropriately large. Integrating by parts if $|t| - d^+(y,x)$ and $|t| - d^-(y,x)$ is suitably large, and then taking in absolute values gives the required bounds for each of the terms $S\!_\alpha$, completing the proof of the required bounds.

% If d(x_0,x) << 1, then the bound says << R^{-N} for all N
% If d(x_0,x) >> 1, then the bound says << R^{(d+1)/2} < ... >^{-N}

Now we address the case $|t_0| \leq \varepsilon_X$. Lemmas \ref{PseudoOsicllatoryLemma} and \ref{lemma:WaveOscillatoryLemmaddw} imply that if we define
%
\begin{equation}
    S\!_\alpha = \int c(t) (Q_\alpha \circ W_\alpha(t) \circ Q_\alpha) \{ u_\alpha \}\; dt,
\end{equation}
%
where $Q_\alpha$ is as above, and
%
\[ W_\alpha(x,y) = R^d \int s(t,x,y,\theta) e^{i [ \phi(x,y,\xi) + t p(y,\xi) ]}\; d\xi, \]
%
where $s$ is smooth and supported on $L^{-1} \leq |\theta| \leq L$, and $\phi$ is a solution to the Eikonal equation \eqref{awiodjawoidhjioq23412341234234}, then for all $N \geq 0$,
%
\begin{equation} \label{parametrixerrroestimate2}
    \left\| S - \textstyle\sum\nolimits_\alpha S\!_\alpha \right\|_{L^\infty(X)} \lesssim_N R^{-N}.
\end{equation}
%
%This error is negligible to the pointwise bounds we want to obtain in Proposition \ref{theMainEstimatesForWave} if we choose $N \geq K - \frac{d+1}{2}$, since the compactness of $X$ implies that $d_X(x,x_0) \lesssim 1$ for all $x \in X$, and so
%
%\begin{equation}
%    R^{-N} \lesssim R^{\left( \frac{d+1}{2} - K \right)} \lesssim \frac{R^{d}}{\langle R d_X(x,x_0) \rangle^{\frac{d-1}{2}}} \Big\langle R \big| |t_0| \pm d_X^\pm(x,x_0) \big| \Big\rangle^{-K}.
%\end{equation}
%
The error in \eqref{parametrixerrroestimate2} is again negligible. We bound each of the functions $\{ S\!_\alpha \}$ separately, combining the estimates using the triangle inequality. We continue by expanding out the implicit integrals in the definition of $S\!_\alpha$. In the coordinate system $U_\alpha$, we can write
%
\begin{equation} \label{SalphaDefinition}
\begin{split}
    S\!_\alpha(x) &= \int c(t) \sigma(x,\eta) e^{2 \pi i \eta \cdot (x - y)}\\[-6 pt]
    &\quad\quad\quad s(t,y,z,\xi) e^{2 \pi i [ \phi(y,z,\xi) + t p(z,\xi) ]}\\
    &\quad\quad\quad\quad \sigma(z,\theta) e^{2 \pi i \theta \cdot (z - w)} (\eta_\alpha u)(w)\\
    &\quad\quad\quad\quad\quad dt\; dy\; dz\; dw\; d\theta\; d\xi\; d\eta.
\end{split}
\end{equation}
%
The integral in \eqref{SalphaDefinition} looks highly complicated, but can be simplified considerably by noticing that most variables are quite highly localized. In particular, oscillation in the $\eta$ variable implies that the amplitude is negligible unless $|x - y| \lesssim 1/R$, oscillation in the $\theta$ variable implies that the amplitude is negligible unless $|z - w| \lesssim 1/R$, and the support of $u$ implies that $|w - x_0| \lesssim 1/R$. Define
%
\begin{equation} \label{DIOAJVIOEJAV8318923}
    k_1(t,x,z,\xi) = \int \sigma(x,\eta) s(t,y,z,\xi) e^{2 \pi i [ \eta \cdot (x - y) + \phi(y,z,\xi) - \phi(x,z,\xi) ]}\; dy\; d\eta,
\end{equation}
%
and
%
\begin{equation} \label{DWAIOCWOAIJFAIO213123}
\begin{split}
    k_2(t,\xi) &= \int k_1(t,x,z,\xi) \sigma(z,\theta) (\eta_\alpha u)(w)\\
    &\quad\quad\quad e^{2 \pi i [ \theta \cdot (z - w) + \phi(x,z,\xi) - \phi(x,x_0,\xi) + t p(z,\xi) - t p(x_0,\xi) ]}\; d\theta\; dw,
\end{split}
\end{equation}
%
and then set
%
\begin{equation} \label{oaisdjoai9091390}
\begin{split}
    a(x,\xi) &= \int c(t) k_2(t,R \xi) e^{2 \pi i [ (t - t_0) p(x_0, R \xi) ]} \; dt\; dz,
\end{split}
\end{equation}
%
so that $\text{supp}_\xi(a) \subset \{ \xi : 1/8 \leq |\xi| \leq 8 \}$, and
%
\begin{equation}
    S\!_\alpha(x) = R^d \int a(x, \xi) e^{2 \pi i R [ \phi(x,x_0,\xi) + t_0 p(x_0,\xi) ]}\; d\xi.
\end{equation}
%
Integrating by parts in $\eta$ and $\theta$ in \eqref{DIOAJVIOEJAV8318923} and \eqref{DWAIOCWOAIJFAIO213123} gives that for all multi-indices $\alpha$,
%
\begin{equation} \label{ioqejfoieqjf13412}
    |\partial_\xi^\alpha k_1(t,x,z,\xi)| \lesssim_\alpha R^{-|\alpha|} \quad\text{and}\quad |\partial_\xi^\alpha k_2(z,\xi)| \lesssim_{\alpha} R^{-|\alpha|}.
\end{equation}
%
Using the bounds in \eqref{ioqejfoieqjf13412} with the fact that $\text{supp}(c)$ is contained in a $O(1/R)$ neighborhood of $t_0$ in \eqref{oaisdjoai9091390} then implies $|\partial_\xi^\alpha a(x,\xi)| \lesssim_\alpha 1$ for all $\alpha$.
%
%We now find $\lambda: V_\alpha^* \times S^{d-1} \to (0,\infty)$ such that
%
%\[ p(x_0, \lambda(x_0,\xi) \xi ) = 1, \]
%
%and switch coordinate systems. If $\tilde{a}(x,\rho, \xi) = a(x, \rho \lambda(x_0) \xi ) (J_\xi \lambda)(x_0,\xi)$,
%a smooth family of homogeneous diffeomorphisms $F_{x_0}: \RR^d \to \RR^d$ for $x_0 \in V_\alpha^*$ such that $p(x_0,F_{x_0}(\xi)) = |\xi|$ for all $x \in \RR^d$. Then if $\tilde{a}(x,\rho, \eta) = a(x, \rho F_{x_0}(\eta) ) JF_{x_0}(\eta)$,
%then a change of variables $\xi = \lambda(x_0,\xi) \rho \eta$ for $|\eta| = 1$ gives that
%
%\begin{align*} 
%    &R^{d} \int a(x,\xi) e^{2 \pi i R [ \phi(x,x_0,\xi) + t_0 p(x_0,\xi) ]}\\
%    &\quad\quad\quad = R^d \int_0^\infty \rho^{d-1} \int_{|\eta| = 1} \tilde{a}(x,\rho,\eta) e^{2 \pi i R \rho [ \lambda(x_0,\eta) \phi(x, x_0, \eta) + t_0 ]}\; d\eta\; d\rho.
%\end{align*}
%

We now account for angular oscillation of the integral by working in a kind of 'polar coordinate' system. First we find $\lambda: V_\alpha \times S^{d-1} \to (0,\infty)$ such that for all $|\xi| = 1$,
%
\begin{equation}
    p(x_0, \lambda(x_0,\xi) \xi) = 1.
\end{equation}
%
If $\tilde{a}(x,\rho, \eta) = a(x, \rho \lambda(x_0) \xi ) \det [ \lambda(x_0,\xi) I + \xi (\nabla_\xi \lambda)(x_0,\xi)^T ]$, then
%
% F_{x_0}(xi) = L(x_0,xi) xi
% DF = L(x_0,xi) I + D_xi lambda
%
\begin{equation}
    S\!_\alpha(x) = R^d \int_0^\infty \rho^{d-1} \int_{|\xi| = 1} \tilde{a}(x,\rho, \xi) e^{2 \pi i R \rho [ t_0 + \phi(x, x_0, \lambda(x_0,\xi) \xi) ]}\; d\xi\; d\rho.
\end{equation}
%
Define $\Phi: S^{d-1} \to \RR$ by setting $\Phi(\xi) = \phi(x,x_0, \lambda(x_0,\xi) \xi)$.    
%
%\[ \text{Hess}_\xi(\Phi) = \text{Hess}_\xi(\phi) + t_0 \text{Hess}_\xi(p). \]
%
%For any multi-index $\alpha$,
%
%\[ |\partial_\xi^\alpha \{ \phi(x,x_0,\xi) - (x - x_0) \cdot \xi \}| \lesssim |x - x_0|^2 |\xi|^{1 - |\alpha|}, \]
%
%and so $\text{Hess}_\xi(\Phi)$ differs from $t_0 \text{Hess}_\xi(p)$ by a matrix all of whose entries are $O(|x - x_0|^2)$. The cosphere curvature assumption on $p$ implies that
%
%\[ |\text{Det}(\text{Hess}_{\xi} p)(x,\xi)| \sim 1. \]
%
%On the support of $s$, $|x - x_0| \lesssim |t|$. Thus if $\varepsilon_X$ is chosen appropriately small,
%
%\[ |\text{Det}(\text{Hess}_{\xi} \Phi)|  \gtrsim t^{d-1}. \]
%
%We claim that $(\nabla_\xi \Phi)(x,x_0,\xi) = 0$ if and only if $x$ lies on the characteristic curve through $x_0$ with cotangent vector $\xi$, and then
%
%To prove this, we rely on the property that, if we define the Hamiltonian flow $\alpha: (-\varepsilon_X, \varepsilon_X) \times T^* V_\alpha^* \to U_\alpha$ generated by $p$, then $\phi(x,x_0,\xi) = t p(x_0,\xi)$ if $x = \alpha(t,x',\xi')$, where $(x' - x) \cdot \xi = 0$ and $p(x',\xi') = p(x_0,\xi)$.
%
% For t_0 = 0, the geodesic from x_0 to x with covextor xi is the
% unique critical point.
%
% nabla_xi phi(x,x_0,xi) = Proj_{xi^Perp}(x - x_0) + O( |x - x_0|^2 )
% nabla_xi Phi = Proj_{xi^Perp}(x - x_0) + t_0 p_xi(x_0,xi) + O( |x - x_0|^2 )
%
% For each t_0, x_0, x, exists a unique xi
% t_0 = 0, then we pick xi going from x_0 to x.
%
% If we rewrite in radial coordinates
%       (t_0,r,x^,x_0)
% Provided that D_{x^} nabla_xi Phi is invertible, this is possible
%
%       phi(x,x_0,xi)
%
%   (D_{x^} nabla_xi) phi(x,x_0,xi) = D_xi [nabla_{x^} phi(x,x_0,xi)]
%                
%
%
%                   p(x, Nab_r phi, Nab_{x^} phi ) = p(x_0,xi)
%
%
% f(x,y) = 0 -> y = g(x) possible if D_yf is invertible
%
% (t(xi) + t_0) p(x_0,xi)
%
% Certainly the geodesic from x_0 to x with covector xi_0 minimizes t(xi) p(x_0,xi)
%   This would also work if p(x_0,xi) is maximized for |xi| = 1 at xi_0
%   Otherwise 
%
% Derivative is (t(xi) + t_0) ∇L(xi) + ∇t(xi) L(xi) = 0
%
% Action is (d_v L)(x,v) v
% Principle of Least Action: A(c) = int (d_v L)(c_x,c_v) c_v
%       Motion is critical point of action.
%
% H(x,xi) = xi * v - L(x,v)
%
% Action then becomes int c_xi c_v = int c_xi p_xi(c_x,c_xi)
%                                  = int p(c_x,c_xi)
%
% Given P as our Hamiltonian
%       P: T^*M -> R
%       P = Legendre Transform of L : TM -> R
%       L = Legendre Transform of P
%
%       If D_xi p(x,xi) = v
%       L(x,v) = v * xi - p(x,xi)
%
% p: R^n x R^n -> R
% psi: R^{n-1} -> R
%       where p(0,eta) = 0 and (Nabla_eta p)(0,eta) * e_n != 0
%       where (Nabla_x psi)(0) = eta'
%
% Then we can solve p(x, Nabla_x phi) = 0
%   such that phi(x',0) = psi(x')
%   and Nabla_x phi(0) = eta
%
% By the implicit function theorem, the assumptions
% uniquely determine d_x phi(x',0) = omega(x')
% in a neighborhood of 0.
%
% We start by finding a Lagrangian section of T^*M,
% which is subset of Z(p), and which contains
% (x',0,omega(x')) for all x' in a neighborhood of 0.
%
% Since Z(p) is a coisotropic submanifold, it is
% foliated by integral curves of the Hamiltonian
% vector field X_p. Find a Lagrangian manifold of R^n
% contained in Z(p), passing through (0,eta)
%
% By assumption, in a neighborhood of
% (0,eta) each of these integral curves of X_p
% projects onto a curve on R^n which is transverse
% to R^{n-1} x {0}. If we let S be the union of all
% the characteristics passing through (x',0,omega(x'))
% then S will therefore be a section of R^n.
%
% The collection (x',omega(x')) is a Lagrangian
% section of R^{n-1} x R^{n-1}, and thus is an
% isotropic submanifold M of R^n x R^n
%
% Thus TM is contained in (TM)^perp
% And the integral curves are perpendicular to
% TM since M is contained in Z(p), which
% implies the union of the curves is Lagrangian
%
% But now we've defined S, we can find phi such
% that d_x phi is S. 
%
%
% So in particular, if phi(x',0) = 0
% So vector field is perpendicular to R^{n-1}
% 
% c(0) = (q,p)
%
% F(c_1(t),y,xi) = int dF(c_1) c_1'
%           = int dF(c_1){ p_xi(c) }
%           = int c_2 { p_xi(c) }
%           = - int p(c)
%           = - t p(y,xi)
%
%The fact that $\Sigma_{x_0}$ has non-vanishing curvature means that 
%
%\[ \text{Det} ( \text{Hess}_{\hat{\eta}} \Phi ) \gtrsim |x - x_0|^{d-1}. \]
%In particular, if $\varepsilon_X$ is chosen suitably small, then the error terms are negligible. 
%
%Now the oscillatory integral has two critical points, at values $\eta$ such that $F_{x_0}(\eta)$ points directly towards or away the flow from $x_0$ to $x$. Thus the integral above can be written as
%
We claim that, if $\varepsilon_X'$ is chosen appropriately small, then in the $\xi$ variable, $\Phi$ has exactly two critical points $|\xi^+|^{-1} \xi^+$ and $|\xi^-|^{-1} \xi^-$, where $\xi^+ \in S\!_{x_0}^*$ is the covector corresponding to the forward geodesic from $x_0$ to $x$, and $\xi^- \in S\!_{x_0}^*$ is the covector corresponding to the backward geodesic from $x_0$ to $x$. Moreover,
%
\begin{equation}
    \Phi(|\xi^+|^{-1} \xi^+) = d_X^+(x_0,x) \quad\text{and}\quad \Phi(|\xi^-|^{-1} \xi^-) = - d_X^-(x_0,x),
\end{equation}
%
and the Hessian at each of these points is non-degenerate, with each eigenvalue of the Hessian having magnitude exceeding a constant multiple of $d_X^{\pm}(x_0,x)$. We prove that these properties hold for $\Phi$ in Proposition \ref{triangleLemma} of the following section, via a series of geometric arguments. It then follows from the principle of stationary phase that
%
\begin{equation}
    S\!_\alpha(x) = \sum_{\pm} \frac{R^{d}}{\left\langle R d_X^{\pm}(x_0,x) \right\rangle^{\frac{d-1}{2}}} \int_0^\infty \rho^{\frac{d-1}{2}} a_{\pm}(x,\rho) e^{2 \pi i R \rho [ t_0 \pm d_X^{\pm}(x_0,x)]}\; d\rho,
\end{equation}
%
where $a_{\pm}$ is supported on $|\rho| \sim 1$, and for all $\alpha$, $|\partial_\rho^\alpha a_{\pm}| \lesssim_\alpha 1$. Integrating by parts in the $\rho$ variable if $t_0 \pm d_X^{\pm}(x_0,x)$ is large, we conclude that
%
% t_0 - d^
%
% 
% 
%
\begin{equation} \label{finaloscillatoryintegralbound}
\begin{split}
    |S\!_\alpha(x)| \lesssim \frac{R^{d}}{\left\langle R d_X(x_0,x) \right\rangle^{\frac{d-1}{2}}} \sum_{\pm} \big\langle R |t_0 \pm d_X(x_0,x)| \big\rangle^{-K}.
\end{split}
\end{equation}
%
Combining \eqref{parametrixerrroestimate2} and \eqref{finaloscillatoryintegralbound} completes the proof of the pointwise bounds.

The quasi-orthogonality arguments are obtained by a largely analogous method, and so we only sketch the proof. Write $S\!_\nu$ for $S\!_{x_\nu,t_\nu}$. One major difference is that we can use the self-adjointness of the operators $Q$, and the unitary group structure of $\{ e^{2 \pi i t P} \}$, to write
%
\begin{equation}
\begin{split}
    \langle S\!_0, S\!_1 \rangle &= \int c_0(t) c_1(s) \big\langle (e^{2 \pi i t P} \circ Q) \{ u_0 \}, (e^{2 \pi i s P} \circ Q) \{ u_1 \} \big\rangle\\
    &= \int c_0(t) c_1(s) \big\langle (e^{2 \pi i (t - s) P} \circ Q^2) \{ u_0 \}, u_1 \big\rangle\\
    &= \int c(t) \big\langle (e^{2 \pi i t P} \circ Q^2) \{ u_0 \}, u_1 \big\rangle,
\end{split}
\end{equation}
%
where $c(t) = \int c_0(u) c_1(u - t)\; du$, by Young's inequality, satisfies
%
\begin{equation}
    \| c \|_{L^1(\RR)} \lesssim \| c_0 \|_{L^1(\RR)} \| c_1 \|_{L^1(\RR)} \leq 1
\end{equation}
%
and $\supp(c) \subset [ (t_0 - t_1) - 4/R, (t_0 - t_1) + 4/R]$. After this, one proceeds exactly as in the proof of the pointwise estimate. We write the inner product as
%
\begin{equation}
    \sum\nolimits_\alpha \int c(t) \big\langle (e^{2 \pi i t P} \circ Q^2) \{ \eta_\alpha u_0 \}, u_1 \big\rangle.
\end{equation}
%
Then we use Lemmas \ref{PseudoOsicllatoryLemma} and \ref{lemma:WaveOscillatoryLemmaddw} to replace $e^{2 \pi i tP} \circ Q^2$ with $Q_{\alpha}^2 \circ W_{\alpha}(t) \circ Q_{\alpha}^2$, modulo a negligible error. The integral
%
\begin{equation}
    \sum\nolimits_\alpha \int c(t) \big\langle (Q_{\alpha}^2 \circ W_{\alpha}(t) \circ Q_{\alpha}^2) \{ \eta_\alpha u_0 \}, u_1 \big\rangle
\end{equation}
%
is then only non-zero if both the supports of $u_0$ and $u_1$ are compactly contained in $U_\alpha$. Thus we can switch to the coordinate system of $U_\alpha$, in which we can express the inner product by oscillatory integrals of the exact same kind as those occurring in the pointwise estimate. Integrating away the highly localized variables as in the pointwise case, and then applying stationary phase in polar coordinates proves the required estimates.
\end{proof}

In remains to classify the critical points that arose in Proposition \ref{theMainEstimatesForWave}.

\begin{prop} \label{triangleLemma}
    Fix a bounded open set $U_0 \subset \RR^d$. Consider a Finsler metric $F: U_0 \times \RR^d \to [0,\infty)$ on $U_0$, and it's dual metric $F_*: U_0 \times \RR^d \to [0,\infty)$, which extends to a Finsler metric on an open set containing the closure of $U_0$. Fix a suitably small constant $r > 0$. Let $U$ be an open subset of $U_0$ with diameter at most $r$ which is geodesically convex (any two points are joined by a minimizing geodesic). Let $\phi: U \times U \times \RR^d \to \RR$ solve the eikonal equation
    %
    \[ F_* ( x, \nabla_x \phi(x,y,\xi) ) = F_*(y,\xi), \]
    %
    such that $\phi(x,y,\xi) = 0$ for $x \in H(y,\xi)$, where $H(y, \xi) = \{ x \in U : \xi \cdot (x - y) = 0 \}$. For each $x_0,x_1 \in U$, let $S\!_{x_0}^* = \{ \xi \in \RR^d: F_*(x_0,\xi) = 1 \}$ be the cosphere at $x_0$, and define $\Psi: S\!_{x_0}^* \to \RR$ by setting
    %
    \[ \Psi(\xi) = \phi(x_1,x_0,\xi). \]
    %
    Then the function $\Psi$ has exactly two critical points, at $\xi^+$ and $\xi^-$, where the Legendre transform of $\xi^+$ is the tangent vector of the forward geodesic from $x_0$ to $x_1$, and the Legendre transform of $\xi^-$ is the tangent vector of the backward geodesic from $x_1$ to $x_0$. Moreover,
    %
    \[ \Psi(\xi^+) = d_X^+(x_0,x_1) \quad\text{and}\quad \Psi(\xi^-) = - d_X^-(x_0,x_1), \]
    %
    and the Hessians $H_+$ and $H_-$ of $\Psi$ at these critical points, viewed as quadratic maps from $T_{\xi_{\pm}} S\!_{x_0}^* \to \RR$ satisfy
    %
    \[ H_+(\zeta) \geq C d_X^+(x_0,x_1) |\zeta| \quad\text{and}\quad H_-(\zeta) \leq - C d_X^-(x_0,x_1) |\zeta|, \]
    %
    where the implicit constant is uniform in $x_0$ and $x_1$.
\end{prop}

If $\Psi$ is as above, then the function $\Phi: S^{d-1} \to \RR$ obtained by setting $\Phi(\xi) = \phi( x, x_0, F_*(x,\xi)^{-1} \xi  )$ is precisely the kind of function that arose as a phase in Proposition \ref{theMainEstimatesForWave}, where $F_*$ was the principal symbol $p$ of the pseudodifferential operator we were considering. Since critical points and the Hessians of maps at critical points are stable under diffeomorphisms, %(see Chapter 5, Problem 17 of \cite{Spivak1}),
and the map $\xi \mapsto F_*(x,\xi)^{-1} \xi$ is a diffeomorphism from $S\!_{x_0}^*$ to $S^{d-1}$, classifying the critical points of the map $\Psi$ implies the required properties of the map $\Phi$ used in Proposition \ref{theMainEstimatesForWave}.

% then, because critical points and the Hessians of maps at critical points are stable under diffeor

%Define a function $\lambda: U \times S^{d-1} \to \RR$ by setting $\lambda(x,v) = F_*( x,v )^{-1}$ and then define $\Phi: S^{d-1} \to \RR$ by setting $\Phi(\xi) = \phi(x,x_0,\lambda(x_0,\xi) \xi)$. Let $\xi^+$ and $\xi^-$ are the two points in $S\!_{x_0}^*$ such that $\mathcal{L}^{-1}(x_0,\xi^+)$ is the unit tangent vector of the forward geodesic from $x_0$ to $x$, and $-\mathcal{L}^{-1}(x_0,\xi^-)$ is the unit tangent vector to the backward geodesic from $x_0$ to $x$. In this subsection, we will verify that the only critical points of $\Phi$ occur at $|\xi^+|^{-1} \xi^+$ and $|\xi^-|^{-1} \xi^-$, that $\Phi( |\xi^+|^{-1} \xi^+) = d_X^+(x_0,x)$ and $\Phi( |\xi^-|^{-1} \xi^-) = - d_X^-(x_0,x)$, and that if we let $V_+$ and $V_-$ be the subspaces of $\RR^d$ which give the tangent spaces of $S^{d-1}$ at each critical point, then the Hessians $H_{\pm} : V_{\pm} \to \RR$ of $\Phi$ at each critical point are non-degenerate, with $|H_{\pm}(\omega)| \gtrsim d_X^{\pm}(x_0,x) |\omega|$, where the implicit constant is locally uniform in $x_0$ and $x$. These properties precisely prove the properties we needed to analyze the function $\Phi$ occuring in Proposition \ref{theMainEstimatesForWave}, where $F_*$ is the principal symbol $p$ of the pseudodifferential operator we are considering.

%We will find it more geometrically natural to work with the function $\Psi: S\!_{x_0}^* \to \RR$ given by $\Psi(\xi) = \phi(x,x_0,\xi)$. Then $\Phi( \xi ) = \Psi( \lambda(x_0,\xi) \xi )$. The map $\xi \mapsto \lambda(x_0,\xi) \xi$ is a diffeomorphism from $S^{d-1}$ to $S\!_{x_0}^*$. Both critical points . Thus it suffices to prove that the only critical points of $\Psi$ occur at $\xi^+$ and $\xi^-$, that $\Psi(\xi_{\pm}) = \pm d_X^{\pm}(x_0,x)$, and that the Hessian of $\Psi$ is appropriately non-degenerate.

%It is simpler to define $\Sigma(x_0,\xi)$ when there is a Riemannian metric $g$ on $U_0$ such that $F(x,v)^2 = \sum g_{ij}(x) v^i v^j$. In this case we take a system of normal coordinates around $x_0$, and define $\Sigma(x_0,\xi)$ to be the hyperplane through the origin in these coordinates perpendicular to $\xi$.  More precisely, we consider the exponential map $\exp: W \to U$, where $W$ is an open subset of $U_0 \times \RR^d$ containing $U_0 \times \{ 0 \}$, defined so that for each $x_0 \in U_0$ and each $u \in \RR^d$, the curve $c(t) = \exp(x_0,tv)$ is a geodesic where it is well defined, i.e. solving the system
%
%\[ \ddot{c}^a = - \sum\nolimits_{j,k} \Gamma^{a}_{jk}(c) \dot{c}^j \dot{c}^k, \]
%
%with the initial conditions $c(0) = x_0$ and $c'(0) = v$. For each $\xi \in \RR^d - \{ 0 \}$, we consider the hyperplane $H_\xi \subset \RR^d$ with normal vector $\xi$, and then define $\Sigma(x_0,\xi) = \exp(x_0,H_\xi)$, which is a hypersurface perpendicular to $\xi$ since $D_v \exp(x_0,0)$ is the identity matrix. % In other words, $\Sigma(x_0,\xi)$ is the hypersurface which, in normal coordinates at $x_0$, forms a hyperplane normal to $\xi$. Since normal coordinates are smooth, and smoothly depend on $x_0$, the family of hypersurfaces $\Sigma(x_0,\xi)$ is then a smooth function of $x_0$ and $\xi$.

%We would like to use the same definition in the Finsler setting. However, the exponential map on a Finsler manifold is in general only everywhere $C^1$. %\footnote[1]{In general the exponential map is only $C^1$ unless $M$ is a \emph{Berwald Finsler manifold}, as in \cite{AkbarZadeh}.}
% Thus the surfaces $\Sigma(x_0,\xi)$ will only be $C^1$, and thus the phase $\phi$ will only be $C^1$, and thus not be smooth enough to yield a parametrix for the half-wave equation.
%
%This argument is not significantly more complex in the Finsler manifold setting than if the operator $P$ gave $M$ a Riemannian metric rather than just a Finsler metric (e.g. for the operators associated with zonal multipliers on the sphere). But we must adapt certain results in the Riemannian manifold literature to the Finsler manifold setting, which does require some extra proof. We relegate these proofs to the appendix when necessary, mentioning citations for the required result in the Riemannian manifold literature that we are adapting.
%A fix is provided by using a kind of normal coordinates at a point adapted to a particular direction, defined in terms of the \emph{autoparallel exponential map} introduced in \cite{Pfeifer}. %, though related to older methods of Douglas and Thomas \cite{Douglas,Thomas}.
%This exponential map is given by $\text{Exp}: W \to U \times \RR^d$, where $W$ is an open subset of $U_0 \times \RR^d \times \RR^d$ containing $U_0 \times \{ 0 \} \times \{ 0 \}$, and smooth away from $U_0 \times \RR^d \times \{ 0 \}$, such that for each $x_0 \in V$, and each $(v,\xi) \in \RR^d \times \RR^d$, the pair of curves $(c(t), s(t)) = \text{Exp}(x_0,tv,\xi)$ solves the system
%%
%\[ \ddot{c}^a = - \sum\nolimits_{j,k} \Gamma^a_{jk}(c,s) \dot{c}^j \dot{c}^k \quad\text{and}\quad \dot{s}^a = - \sum\nolimits_{j,k} \Gamma^a_{jk}(c,s) \dot{c}^j s^k, \]
%
%such that $c(0) = x_0$, $\dot{c}(0) = v$, and where $s(0) = \mathcal{L}^{-1}(x_0,\xi)$. Because of the choice of initial conditions here, if we let $\pi: U \times \RR^d \to U$ be the standard projection map, then $D_v(\pi \circ \text{Exp})(x_0, 0, \xi)$ is the identity, and so the map $G_{x_0,\xi} = (\pi \circ \text{Exp})(x_0,\cdot,\xi)$ is a diffeomorphism onto a neighborhood of $x_0$. % and so $E_{x_0,\xi} = (\pi \circ \exp)(x_0,\cdot,\xi)$ is a diffeomorphism in a neighborhood of the origin. If we assume $V$ to have small enough diameter, we may assume that $E_{x_0,\xi}$ is a diffeomorphism onto an open set containing $V$ for all $x_0$ and $\xi$. % We use this diffeomorphism to define a covector field $\omega$ such that $E_{x_0,\xi}^* \{ \omega \}$ is the constant covector field that everywhere takes the value $\xi$. Now we can obtain a Riemannian metric $h(x_0,\xi, \cdot)$ on $V$ via the coefficients $h^{ij}(x_0, \xi, x) = g^{ij}( x_0, \omega(x_0) )$, where $g^{ij}$ are the coefficients corresponding to Riemannian approximations of the dual metric $F_*$. We finally take a normal coordinate system $F_{x_0,\xi}$ for the metric $h$ and define 
%We define
%
%\[ \Sigma(x_0,\xi) = G_{x_0,\xi}(H_\xi), \]
%
%where $H_\xi$ is the hyperplane in $\RR^d$ perpendicular to $\xi$.

%We note that $G_{x_0,\xi}$ is in general only defined locally, which is why we must work with sufficiently small open sets $U \subset U_0$ such that for all $x_0 \in U$ and $\xi \in \RR^d$, the map $G_{x_0,\xi}$ is a diffeomorphism onto $U$. We will also assume that $U$ is small enough that each pair of points in $U$ is connected by a unique forward geodesic. This is an unproblematic assumption for the application of our arguments to Proposition \ref{theMainEstimatesForWave}, since there we were able to take an arbitrarily fine partition of unity before switching into coordinates.% Since $DE_{x_0,\xi}(0) = I$, the hypersurface $\Sigma(x_0,\xi)$ is perpendicular to $\xi$ at $x_0$, and this definition gives a smooth family of smooth hypersurfaces for any Finsler manifold.

%(TODO: does this formula look better in cotangent coordinates? ). We have need of using this exponential map is because the standard exponential map, defined in terms of geodesics, and which we can write in terms of the autoparallel exponential map as
%
%\[ (x_0,u) \mapsto \exp(x_0, u, u), \]
%
%fails to be smooth when $u = 0$ on a general Finsler manifold. On the other hand, the auto-parallel exponential map $\exp(x_0,u,v)$ is smooth away from $v = 0$. For each $x_0$ and $v \neq 0$, the inverse of the map map $u \mapsto \exp(x_0,u,v)$ gives a smooth coordinate system in a neicghborhood of $x_0$, and provides a substitute for normal coordinates, at least when in comes to geodesics pointing in the direction $v$. If 

%Now we can define $\Sigma(x_0,\xi)$ for $\xi \in T^*_{x_0} M - \{ 0 \}$. Let $v \in \RR^d$ be the Legendre transform of $\xi$ at $x_0$, i.e. the vector $v$ such that $\xi = \sum g_{ij}(x_0,v) v^j$, or equivalently, if we define
%
%\[ g^{ij} = \frac{1}{2} \frac{\partial^2 F_*}{\partial \xi^i \partial \xi^j}, \]
%
%then $v^i = \sum g^{ij}(x_0,\xi) \xi_j$. If we consider the coordinate system given by the inverse of $u \mapsto \exp(x_0,u,v)$, then the hypersurface $\Sigma(x_0,\xi)$ is then precisely the surface which in this coordinate system is the unique \emph{hyperplane} conormal to $\xi$.

%If we fix $\alpha$, then for each $x_0 \in U_\alpha$, and each $\xi \in T^*_{x_0} M$, we will also need to define an additional coordinate system $z(\cdot,x_0,\xi)$ defined in a neighborhood of $x$, which is an analogue of normal coordinates for Finsler manifolds called \emph{Douglas-Thompson normal coordinates}. Like normal coordinates, defined in terms of a system of ordinary differential equations. Namely, we have $z(x,x_0,\xi) = z$, if and only if the unique solution to the system
%
%\[ (c^i)''(t) = - \sum\nolimits_{a,b} \gamma^i_{ab}(c,s) (c^a)'(t) (c^b)'(t) \quad\text{and}\quad s'(t) = - \sum \gamma^i_{ab}(c,s) (c^a)'(t) s^b(t) \]
%
%with the initial conditions $c(0) = x_0$, $c'(0) = z$, and $s(0) = \xi$ has $c(1) = x$. If 

%\begin{remark}
%    Using the notation in Proposition \ref{theMainEstimatesForWave}, if $\alpha: S^{d-1} \to S\!_x^*$ is given by $\alpha(\xi) = \lambda(x_0,\xi) \xi$, then $(\Psi \circ \alpha)(\xi) = \Phi(\xi)$. Then $\alpha$ is a diffeomorphism, and so it follows from Proposition \ref{triangleLemma} that the critical points of $\Phi$ are equal to $\alpha^{-1}(\pm \xi_0)$, where $\xi_0$ is the unique covector in $S\!_x^*$ corresponding to the geodesic from $x_0$ to $x_1$. Since the Hessian of a function is a diffeomorphism invariant at critical points of a manifold, it also follows from Proposition \ref{theMainEstimatesForWave} that the Hessian of $\Phi$ at $\alpha^{-1}(\pm \xi_0)$ is non-degenerate, with each eigenvalue having magnitude exceeding a constant multiple of 

%    In the statement of Proposition \ref{triangleLemma}, we have applied a change of coordinates as compared to the application
%\end{remark}

In order to prove \ref{triangleLemma}, we rely on a geometric interpretation of $\Psi$ following from Hamilton-Jacobi theory.

\begin{lemma} \label{HamiltonLemma}
    Consider the setup to Proposition \ref{triangleLemma}. For any $\xi \in S\!_{x_0}^*$,
    %
    \[ |\Psi(\xi)| = \begin{cases} \text{the length of the shortest curve from $H(x_0,\xi)$ to $x_1$} & : \text{if}\ \Psi(\xi) > 0, \\ \text{the length of the shortest curve from $x_1$ to $H(x_0,\xi)$} & : \text{if}\ \Psi(\xi) < 0. \end{cases} \]
\end{lemma}
\begin{proof}
    We rely on a construction of $\phi$ from Proposition 3.7 of \cite{Treves2}, which we briefly describe. Fix $x_0$ and $\xi$. Then there is a unique covector field $\omega: H(x_0,\xi) \to \RR^d$ which is everywhere perpendicular to $H(x_0,\xi)$, with $\omega(x_0) = \xi$ and with $F_*(x,\omega(x)) = F_*(x_0,\xi)$ for all $x \in H(x_0,\xi)$. There exists a unique point $x(\xi) \in H(x_0,\xi)$ and a unique $t(\xi) \in \RR$, such that the unit speed geodesic $\gamma$ on $X$ with $\gamma(0) = x(\xi)$ and $\gamma'(0) = \mathcal{L}^{-1}( x(\xi), \omega(x(\xi)) )$ satisfies $\gamma( t(\xi) ) = x_1$. We then have $\Psi(\xi) = t(\xi)$. If $t(\xi)$ is negative, then $\gamma|_{[t(\xi),0]}$ is a geodesic from $x_1$ to $x_0$, and if $t(\xi)$ is positive, $\gamma|_{[0,t(\xi)]}$ is a geodesic from $x_0$ to $x_1$. Because $\gamma$ is a geodesic, the geometric interpretation then follows if $U$ is a suitably small neighborhood such that geodesics are length minimizing.
\end{proof}

% and relies on the fact discussed in the introduction that the Hamiltonian flow of the principal symbol $p$ of $P$ on $M$ is the geodesic flow of the Finsler metric induced by $p$ on $M$. Namely, for $\xi \in S\!_{x_0}$, the value $\psi(\xi)$ is the length of the unique geodesic starting at $x_1$ and ending at a point on $\Sigma(x_0,\xi)$, passing through $\Sigma(x_0,\xi)$ orthogonally. More precisely, there exists a unique point $x(\xi) \in \Sigma(x_0,\xi)$ and a unique value $t(\xi) \in \RR$, such that if $\eta = \eta(\xi)$ is the unique unit covector orthogonal to $\Sigma(x_0,\xi)$ at $x(\xi)$ and oriented outward from $\Sigma(x_0,\xi)$ in the same direction as $\xi$, then $x_1 = \exp_{x(\xi)}(t(\xi) \eta(\xi) )$, and we then have $\psi(\xi) = t(\xi)$.
%



%\begin{figure}[h]
%        \centering
%        \includegraphics[width=0.4\textwidth]{Geodesics.eps}
%\end{figure}

%\noindent That a unique point $x(\xi)$ exists with these properties follows if we choose the diameter of $V$ to be suitably small, depending on the Finsler metric $M$.

% to be smaller than the normal injectivity radius of $\Sigma(x_0,\xi)$ for each $\xi \in S\!_{x_0}$. That the point $x(\xi)$ lies in $U$ follows because $d(\Sigma(x_0,\xi), x_1) \leq d(x_0,x_1)$, and $N(x_1,d(x_0,x_1)) \subset U$. In particular, if all sectional curvatures of $M$ are upper bounded by $\kappa^2$, then $\psi$ exists if we choose the diameter of $U$ to be smaller then $(\pi/2) \kappa^{-1}$, since, by Lemma 2.3 of \cite{Grimaldi}, $(\pi/2) \kappa^{-1}$ is smaller than the normal injectivity radius of $\Sigma(x_0,\xi)$. In particular, this result is satisfied since the diameter of $U$ is bounded by $2.5 \varepsilon_M$, and $\varepsilon_M < 0.4 (\pi/2) \kappa^{-1}$.

It follows immediately from Lemma \ref{HamiltonLemma} that
%
\begin{equation}
    \Psi(\xi_+) = d_X^+(x_0,x_1) \quad\text{and}\quad \Psi(\xi_-) = - d_X^-(x_0,x_1).
\end{equation}
%
A simple geometric argument also shows $\Psi(\xi^+)$ is the maximum value of $\Psi$ on $S\!_{x_0}^*$, and $\Psi(\xi^-)$ is the minimum value on $S\!_{x_0}^*$, so that these two points are both critical. Indeed, the point $x_0$ lies in $H(x_0,\xi)$ for all $\xi \in \RR^d - \{ 0 \}$. Thus the shortest curve from $x_0$ to $x_1$ is always longer than the shortest curve from $H(x_0,\xi)$ to $x_1$. Similarily, the shortest curve from $x_1$ to $x_0$ is always longer than the shortest curve from $x_1$ to $H(x_0,\xi)$. Thus
%
\begin{equation}
    - d_X^-(x_0,x_1) \leq \Psi(\xi) \leq d_X^+(x_0,x_1),
\end{equation}
%
and so $\Psi(\xi^-) \leq \Psi(\xi) \leq \Psi(\xi^+)$ for all $\xi \in $. All that remains is to prove that $\xi^+$ and $\xi^-$ are the \emph{only} critical points of $\Psi$, and that these critical points are appropriately non-degenerate.

%In this first part of the argument, the constant $\varepsilon_X$ need only be smaller than the injectivity radius of the set $U$, which is positive since $U$ is precompact, but in the proof that $\pm \xi_0$ are nondegenerate critical points we may need to pick $\varepsilon_X$ even smaller.

In order to simplify proofs, we employ a structural symmetry to reduce the number of cases we need to analyze. Namely, if one defines the reverse Finsler metric $F_\rho(x,v) = F(x,-v)$, then $F_\rho^*(x,\xi) = F_*(x,-\xi)$, and so the associated function $\Psi^\rho$ which is the analogue of $\Psi$ for $F^\rho$ satisfies $\Psi^\rho(\xi) = -\Psi(-\xi)$. The critical points of $\Psi$ and $\Psi^\rho$ are thus directly related to one another, which allows us without loss of generality to study only points with $\Psi \leq 0$ (and thus only study geodesics beginning at $x_1$).

\begin{proof}[Proof that $\xi^+$ and $\xi^-$ are the only critical points]
    Fix $\xi^* \in T_{x_0} X - \{ \xi^{\pm} \}$. Using the notation defined above, let $x_* = x(\xi^*)$ and $t_* = t(\xi^*)$. Using the symmetry above, we may assume without loss of generality that $\Psi(\xi^*) \leq 0$. Since $\xi^-$ is not perpendicular to $H(x_0,\xi^*)$ at $x_0$, we have $x_* \neq x_0$. If $\Psi(\xi^*) < 0$, let $\gamma$ be the unique unit speed forward geodesic with $\gamma(0) = x_1$ and $\gamma(t_*) = x_*$. If $\Psi(\xi^*) = 0$, let $\gamma$ be the unique unit speed forward geodesic with $\gamma'(0)$ equal to the Legendre transform of $\xi^*$. Pick $\eta$ such that $\eta \cdot (x_* - x_0) \neq 0$, and then, for $t$ suitably close to $t_*$, define a smooth map
    %
    \begin{equation} \xi(t) = \frac{\xi^* + a(t) \eta}{F_*(x_0, \xi^* + a(t) \eta)}, \end{equation}
    %
    into $S\!_{x_0}^*$, where
    %
    \begin{equation} a(t) = - \frac{\xi^* \cdot ( \gamma(t) - x_0 )}{\eta \cdot ( \gamma(t) - x_0 )} \end{equation}
    %
    is defined so that $\gamma(t) \in H(x_0, \xi(t))$. Then $\Psi( \xi(t) ) = -t$, and differentiation at $t = t_*$ gives $D\Psi( \xi^* ) ( \xi'(t_*) ) = -1$. In particular, $D \Psi( \xi^* ) \neq 0$, so $\xi^*$ is not a critical point. \qedhere
    %
    % gamma(t_*) = x_*
    %   xi(t_*) = xi^*
    %
    %  xi(t) ( gamma(t) - x_0 ) = (t - t_*) [ xi'(t_*) [ gamma(t) - x_0 ] + xi^* gamma'(t) ]
    %   xi(t) = xi^* + a(t) eta
    %   xi(t) ( gamma(t) - x_0 ) = xi^* ( gamma(t) - x_0 ) + a(t) eta ( gamma(t) - x_0 )
    %                               = 0 if a(t) = - xi^* ( gamma(t) - x_0 ) / eta ( gamma(t) - x_0 )
    %   Well defined near xi^* if eta ( x_* - x_0 ) != 0
    %       Derivative in t is
    %           a'(0) = - [ [eta ( x_* - x_0 )] [xi^* gamma'(t_*)] / [ eta (x_* - x_0) ]^2 = - 1 / eta (x_* - x_0)
    %   
    %   Which is good provided that xi^* gamma'(t_*) != 0 and eta (x_* - x_0) != 0
    %
    %   And this is easy because xi^* gamma'(t_*) = 1
    %   So as long as eta is not a constant multiple of xi^* we're good.

    % Define xi(t) = xi^* + a xi^+
%    Let $v(t) = \mathcal{L}(\gamma(t), \gamma'(t))$.


    %
    %

%    For $t$ suitably close to $x_0$, we can find a smooth function $\xi(t) \in S\!_{x_0}^*$ with $\xi(0) = \xi^*$, and such that $\gamma(t) \in H(x_0, \xi(t))$ for each $t$. Using the fact that $\gamma|_{[t,t_*]}$ is a curve from $H(x_0,\xi(t))$ to $x_1$ of length $t_* - t$, we find that $\Psi(\xi(t)) \leq t_* - t$. Since $\Psi(\xi(0)) = t_*$, taking $t \to 0^+$ gives $D\Psi(\xi^*)(\xi'(0)) \leq -1$. In particular, $D\Psi(\xi^*) \neq 0$, and so $\xi^*$ is not a critical point. \qedhere
    \end{proof}

We now analyze the non-degeneracy of the critical points $\xi^+$ and $\xi^-$.








%It is here that the precise choice of surfaces $\Sigma(x_0,\xi)$ will aid us because to prove non-degeneracy one must look at the second-order behavior of the function $\Psi$, rather than in the last proof where it was only necessary to study first-order behavior of $\Psi$.

    % For v in T_p M, we get a linear isomorphism
    %
    % d exp_{p,v}: T_p M -> T_{exp_p(v)} M
    %
    % Given by differentiating, identifying
    % T_v T_p M with T_p M in the canonical way.
    %
    % d exp_p is *not* an isometry, but it does satisfy
    %
    % < d exp_{p,v}(v), d exp_{p,v}(w) > = < v, w >.
    %
    % Now define the Curvature Tensor
    %
    % R(X,Y)Z = Nabla_X Nabla_Y Z - Nabla_Y Nabla_X Z - Nabla_{[X,Y]} Z
    %
    % Consider alpha(s,t) = exp_p( (cos(s) v + sin(s) w) t )
    %
    % Let T = alpha_*(d_t), J(t) = alpha_*(d_s|_{(0,t)}).
    %
    % Then J is a Jacobi field, with J(t) being a tangent vector at exp_p( vt )
    %
    % J(0) = 0
    % J'(0) = w
    % J''(0) = R(T,J) T|_0 = 0
    % < J,J >''' = R(T,w) T
    %
    % Let f(t) = < J(t), J(t) >_g
    %
    % Then f(0) = < J(0), J(0) > = < 0, 0 > = 0
    %
    % And f'(0) = 2 < J'(0), J(0) > = 2 < w, 0 > = 0
    %
    % And f''(0) = 2 [ < J''(0), J(0) > + < J'(0), J'(0) > ]
    %            = 2 |w|_g^2
    % 
    % And f'''(0) = 2 [ < J'''(0), J(0) > + 3 < J''(0), J'(0) > ]
    %             = 6 < J''(0), w > = 0
    %
    % And f^(4)(0) = 2 < J^(4)(0), J(0) > + 5 < J'''(0), J'(0) > + 3 < J''(0), J''(0) >
    %              = 5 < J'''(0), J'(0) > 
    %              = 5 < R(T,w) T, w >
    %
    % So we conclude that | J(t) |^2 = t^2 + (5/24) < R(T,w) T, w > t^4
    %
    % For small s, s^{-1} [ alpha(t,s) - alpha(t,0) ] should be
    % close to J(t), so we are saying that
    % | alpha(t,s) - alpha(t,0) |^2 = s^2 [ t^2 + (5/24) < R(T,w) T, w > t^4 + O(t^5) ]
    % In particular, we can guarantee that | alpha(t,s) - alpha(t,0)| ~ st
    %
    % Now alpha(d,0) = x_0, and alpha(t,s) = x
    % and for |t - d| <= C s^2
    %
    % Now | alpha(d,s) - x_0 | ~ sd
    %
    % and | alpha(d,s) - x | <= C s^2
    %
    % so |x - x_0| ~ sd - Cs^2 ~ sd
    %
    % Argument why it must be critical: easy argument it's a maximum
    % because x_0 lies on all of the surfaces Sigma(x_0,xi), so
    % the geodesics from x_1 must hit Sigma(x_0,xi) - { x_0 } before
    % hitting x_0.


    % In particular alpha(t,s) - alpha(t,0) = s [ t^2 + (5/24) < R(T,w) T, w > t^4 + O(t^5) ]

    % 
    % exp_p( ( cos(s) v + sin(s) w ) t )
    % exp_p( ( v - O(s^2)v + sw + O(s^3)w ) t )

    % Consider |dexp_{p,v}(tw)|^2, where v and w are orthonormal. Then
    %
    %   |dexp_{p,v}(tw)|^2 = t^2 - [< R(w, v ) v, w > / 3] t^4 + O(t^5)
    %
    % By polarization identity
    %
    %   < x, y > = (1/2) [  |x + y|^2 - |x|^2 - |y|^2   ]
    %
    % < A(tw),  

\begin{proof}[Proof that $\xi^+$ and $\xi^-$ are non-degenerate]
    Using symmetry, it suffices without loss of generality to analyze the critical point $\xi^-$ rather than $\xi^+$. Let $H_-: T_{\xi^-} S\!_{x_0}^* \to \RR$ be the Hessian of $\Psi$ at $\xi^-$. Let $v_0 = \mathcal{L}_{x_0}^{-1} \xi^-$, and using the notation of the last argument, let $l = t(\xi^-)$. Consider a curve $\xi(a)$ valued in $S\!_{x_0}^*$ with $\xi(0) = \xi^-$ and $\zeta = \xi'(0)$ for some $\zeta \in T_{\xi^-}^* S\!_{x_0}$. Then the second derivative of $\Psi(\xi(a))$ at $a = 0$ is $H_-( \zeta )$, and so our proof would be complete if we could show that the function $L(a) = - \Psi( \xi(a) )$, which is the length of the shortest geodesic from $x_1$ to $H(x_0,\xi(a))$, satisfies $L''(0) \geq C l |\zeta|$, for a constant $C > 0$ uniform in $x_0$, $x_1$, and $\zeta$.

    Consider the partial function $\text{Exp}_{x_1}: \RR^d \to U_0$ obtained from the exponential map at $x_1$. If $r$ is chosen suitably small, there exists a neighborhood $V$ of the origin in $\RR^d$ such that $E = \text{Exp}_{x_1}|_V$ is a diffeomorphism between $V$ and $U$. Unlike in Riemannian manifolds, in general $E$ is only $C^1$ at the origin, though smooth on $V - \{ 0 \}$. However, for $|v| = 1$ and $t > 0$ we can write $E(tv) = (\pi \circ \varphi)( x_1, \mathcal{L}_{x_1} v, t)$, where the partial function $\varphi: (T^* U_0 - 0) \times \RR \to (T^* U_0 - 0)$ is the flow induced by the the Hamiltonian vector field $( \partial_\xi F_*, - \partial_x F_*)$ on $T^* U_0 - 0$, and $\pi$ is the projection map from $T^* U_0 - 0$ to $U_0$. Where defined, $\varphi$ is a smooth function since the Hamiltonian vector field is smooth, and so it follows by homogeneity and the precompactness of $U$ that the partial derivatives $(\partial^\alpha E_x)(v)$ are uniformly bounded for $v \neq 0$ and $x \in U$. It thus follows from the inverse function theorem that there exists a constant $A > 0$ such that for all $x_1$ and $x$ in $U$ with $x \neq x_1$,
    %
    \begin{equation} \label{GBounds}
        |\partial_j G_{x_1}(x)| \leq A \quad\text{and}\quad |(\partial_j \partial_k G_{x_1})(x)| \leq A.
    \end{equation}
    %
    We can also pick $A$ to be large enough that for all $x \in U$, and all $v,w \in \RR^d - \{ 0 \}$,
    %
    \begin{equation}
        A^{-1} |w|^2 \leq \sum\nolimits_{ij} g_{ij}(x,v) w^i w^j \leq A |w|^2.
    \end{equation}
    %
    and such that for all $x \in U$ and $v \in \RR^d - \{ 0 \}$,
    %
    \begin{equation} \label{gijbounds}
        |\partial_{x_k} g_{ij}(x,v)| \leq A.
    \end{equation}
    %
    %With notation now setup, we now prove $H_-$ is appropriately nondegenerate.

    Since $\zeta \in T_{\xi^-} S\!_{x_0}^*$, and $S\!_{x_0}^* = \{ \xi : F_*(x_0,\xi)^2 = 1 \}$, by Euler's homogeneous function theorem we have
    %
    \begin{equation} \label{DIOAWJDIOWAJDOIWAJ14}
        \sum\nolimits_{ij} g^{ij}(x_0,\xi^-) \xi'(0) \xi^-_j = \frac{1}{2} \sum\nolimits_{i,j} \frac{\partial^2 F_*^2}{\partial \xi_i \partial \xi_j}(x_0,\xi^-) \zeta_i \xi^-_j = \frac{1}{2} \sum \frac{\partial F_*^2}{\partial \xi_j}(x_0,\xi^-) \zeta_j = 0.
    \end{equation}
    %
    Differentiating $F_*(x_0,\xi(a))^2 = 1$ twice with respect to $a$ at $a = 0$ yields that
    %
    \begin{equation} \label{AIWODJWAO314213}
         \sum\nolimits_{i,j} g_{ij}(x_0,\xi^-) \xi''_i(0) \xi^-_j = - \sum\nolimits_{i,j} g_{ij}(x_0,\xi^-) \zeta^i \zeta^j
    \end{equation}
    %
    Define vectors $n(a)$ by setting $n^i(a) = \sum g^{ij}(x_0,\xi^-) \xi_j(a)$. Then $n(a)$ is the normal vector to $H(x_0, \xi(a))$ with respect to the inner product with coefficients $g_{ij}(x_0,v_0)$.
    %
%    \begin{equation}
%        H(x_0,\xi(a)) = \left\{ x : \sum\nolimits_{ij} g_{ij}(x_0,v_0) (x^i - x_0^i) n^j(a) = 0 \right\}.
%    \end{equation}
    %
    Let $u(a)$ be the orthogonal projection of $v_0$ onto the hyperplane $\{ v : \xi(a) \cdot v = 0 \}$ with respect to the inner product $g_{ij}(x_0,v_0)$. If we define
    %
    \begin{equation}
        c(a) = \sum g_{ij}(x_0,v_0) v_0^i n^j(a) = \sum g^{ij}(x_0,\xi^-) \xi^-_i \xi_j(a),
    \end{equation}
    %
    then $u(a) = v_0 - c(a) n(a)$. Note that \eqref{DIOAWJDIOWAJDOIWAJ14} and \eqref{AIWODJWAO314213} imply $c(0) = 1$, $c'(0) = 0$, and $c''(0) \leq - |\zeta|^2 / A$. Also $n(0) = v_0$ and $|n'(0)| \leq A |\zeta|$.
    %
    % 1 - c(a)^2 = 1 - ( 1 - a^2 |zeta|^2 / A )^2
    %            = 2 a^2 |zeta|^2 / A

    Let $x(s) = x_0 + s u(a)$ and let $R(s)$ be the length of the geodesic from $x_1$ to $x(s)$. To control $R(s)$, define $y(s) = G(x(s))$, and consider the variation $A(s,t) = E( t y(s) )$, defined so that $t \mapsto A(s,t)$ is the geodesic from $x_1$ to $x(s)$. The Gauss Lemma for Finsler manifolds (see Lemma 6.1.1 of \cite{BaoChern}) implies that
    %
    \begin{equation}
        A^{-1} R(s) \leq |y(s)| \leq A R(s).
    \end{equation}
    %
    Define $T(s) = (\partial_t A)(s,1)$ and $V(s) = (\partial_s A)(s,1)$.
    %
%    \begin{equation}
%        T(s) = (\partial_t A)(s,1) = \sum\nolimits_{i,j} \frac{\partial E^i}{\partial y^j}( y(s) ) y^j(s) e_i \quad\text{and}\quad V(s) = (\partial_s A)(s,1) = u(a).
%    \end{equation}
    %
    Then the first variation formula for geodesics implies
    %
    \begin{equation} \label{RSFirstDerivativeEquation}
        R(s) R'(s) = \sum\nolimits_{i,j} g_{ij}( x(s), T(s) ) V^i(s) T^j(s).
    \end{equation}
    %
    Again, the Gauss Lemma implies
    %
    \begin{equation} \label{Idiawjdiwaj213123}
        A^{-1} R(s) \leq |T(s)| \leq A R(s).
    \end{equation}
    %
    We can write
    %
    \begin{equation}
        T^i(s) = \sum\nolimits_{i,j} (\partial_j E^i)( y(s)) y^j(s)
    \end{equation}
    %
    and
    %
    \begin{equation}
        V^i(s) = \sum\nolimits_{i,j,k} (\partial_j E^i) (y(s)) (\partial_k G^j)( x(s)) u^k(a) = u^i(a).
    \end{equation}
    %
    In particular, $T(0) = v_0$, so $R'(0) = \sum g_{ij}(x_0, v_0) u^i(a) v_0^j = 1 - c(a)^2$. Cauchy-Schwartz applied to \eqref{RSFirstDerivativeEquation} also tells us that
    %
    \begin{equation} \label{wdkawoidj141}
        |R'(s)| \lesssim_A |u(a)|.
    \end{equation}
    %
    Note that $u(0) = 0$, so if $a$ is small enough, then we have $|u(a)| \leq l/2$. Taylor's theorem applied to \eqref{wdkawoidj141}, noting $R(0) = l$ then gives that for $|s| \leq 1$,
    %
    \begin{equation} \label{RBound}
        l/2 \leq R(s) \leq 2l.
    \end{equation}
    %
    Differentiating \eqref{RSFirstDerivativeEquation} tells us that
    %
    \begin{equation} \label{FFFF213123}
    \begin{split}
        R'(s)^2 + R''(s) R(s) &= \sum\nolimits_{i,j,k} \Bigg[ (\partial_{x_k} g_{ij})( x(s), T(s) ) u^i(a) T^j(s) u^k(a) \Bigg]\\
        &\quad\quad\quad\quad + \Bigg[ (\partial_{v_k} g_{ij} )(x(s), T(s)) u^i(a) T^j(s) (\partial_s T^k)(s)   \Bigg]\\
        &\quad\quad\quad\quad\quad\quad + \Bigg[ g_{ij}( x(s), T(s) ) u^i(a) (\partial_s T^j)(s) \Bigg].
    \end{split}
    \end{equation}
    %
    Write the right hand side as $\text{I} + \text{II} + \text{III}$. Using \eqref{gijbounds}, \eqref{Idiawjdiwaj213123}, \eqref{RBound}, and the triangle inequality gives
    %
    \begin{equation} \label{IBound}
        |\text{I}| \lesssim R(s) |u(a)|^2 \lesssim l |u(a)|^2.
    \end{equation}
    %
    Since $\partial_{v_k} g_{ij} = (1/2) (\partial^3F^2 / \partial v_i \partial v_j \partial v_k)$, applying Euler's homogeneous function theorem when summing over $j$ implies that
    %
    \begin{equation} \label{IIBound}
        \text{II} = 0.
    \end{equation}
    %
    Applying Cauchy-Schwarz and \eqref{GBounds}, we find
    %
    \begin{equation} \label{IIIBound}
        |\text{III}| \lesssim |u(a)| |T'(s)| \lesssim |u(a)|^2 [|y(s)| + 1] \lesssim (l + 1) |u(a)|^2.
    \end{equation}
    %
    But now combining \eqref{IBound}, \eqref{IIBound}, \eqref{IIIBound}, and rearranging \eqref{FFFF213123} shows that
    %
    \begin{equation}
        |R''(s)| \lesssim l^{-1} |u(a)|^2 + (1 + l^{-1}) |u(a)|^2 \lesssim l^{-1} |u(a)|^2.
    \end{equation}
    %
    Taylor's theorem implies there exists $B > 0$ depending only on $A$ and $d$ such that
    %
    \begin{equation} \label{WADAWD21312}
        |R(s) - (R(0) + s R'(0))| \leq B l^{-1} |u(a)|^2 s^2.
    \end{equation}
    %
    Since $R(0) = 1$, $R'(0) = 1 - c(a)^2$, $c(0) = 1$, $u(0) = 0$, $c'(0) = 0$, $|u'(0)| \leq A |\zeta|$, and $c''(0) \leq - |\zeta|^2 / A$, we conclude from \eqref{WADAWD21312} that as $a \to 0$, if $s > 0$ then
    %
    \begin{equation}
    \begin{split}
        R(-s) &\leq l - s R'(0) + B l^{-1} |u(a)|^2 s^2\\
        &\leq l - s ( A^{-1} |\zeta|^2 a^2 ) + A^2 B l^{-1} |\zeta|^2 s^2 a^2 + O(a^3 ( s + l^{-1} s^2)).
    \end{split}
    \end{equation}
    %
    % |u(a)|^2 = sum u^i(a)^2
    % Derivative is 2 u . u'(a) = 0
    % Derivative is 2 u' u' <= A^2 |zeta|^2
    For all $s$, $L(a) \leq R(s)$. Optimizing by picking $s = l / 2 A^3 B$ gives
    %
    \begin{equation}
        L(a) \leq R(-s) \leq l - l |\zeta|^2 a^2 / 4 A^4 B + O( a^3 ).
    \end{equation}
    %
    Taking $a \to 0$ and using that $L(0) = l$ gives that $L''(0) \leq - l |\zeta|^2 / 4 A^4 B$, so setting $C = 1/4 A^4 B$, we find we have proved what was required.
\end{proof}

\section{Analysis of Regime I via Density Methods} \label{regime1firstsection}

We now begin obtaining bounds for the operator $T^I$ specified in Proposition \ref{TjbLemma} by using the quasi-orthogonality estimates of Proposition \ref{theMainEstimatesForWave}. Given an input $u: X \to \CC$, we consider a maximal $1/R$ separated subset $\mathcal{X}_R$ of $X$, and then consider a decomposition $u = \sum_{x_0 \in \mathcal{X}_R} u_{x_0}$ with respect to some partition of unity, where $\text{supp}(u_{x_0}) \subset B(x_0,1/R)$. The balls $\{ B(x_0,1/R) : x_0 \in \mathcal{X}_R \}$ have finite overlap, and so
%
\begin{equation}
    \| u \|_{L^p(X)} \sim \left( \sum\nolimits_{x_0 \in \mathcal{X}_R} \| u_{x_0} \|_{L^p(X)}^p \right)^{1/p}.
\end{equation}
%
If we set $S\!_{x_0,t_0} = T_{t_0}^I \{ u_{x_0} \}$, then
%
\begin{equation} \label{DAPOCJAPWOCJAWOIFJOI}
    \left\| T^I u \right\|_{L^p(X)} = \left\| \sum\nolimits_{(x_0,t_0) \in \mathcal{X}_R \times \mathcal{T}_R} S\!_{x_0,t_0} \right\|_{L^p(X)}.
\end{equation}
%
In this subsection, we use the quasi-orthogonality estimates of the last section to obtain $L^2$ estimates on partial sums of the quantities on the right hand side of \eqref{DAPOCJAPWOCJAWOIFJOI}, where the partial sum is taken over a `sparse' subset of indices. We say a set $\mathcal{E} \subset \mathcal{X}_R \times \mathcal{T}_R$ has \emph{density type} $(A_0,A_1)$ if for any set $B \subset \mathcal{X}_R \times \mathcal{T}_R$ with $1/R \leq \text{diam}(B) \leq A_1/R$,
%
\begin{equation}
    \#(\mathcal{E} \cap B) \leq R A_0\; \text{diam}(B). \footnote[1]{This definition of density is chosen because it is `scale-invariant' as we change the parameter $R$, matching the definition given in Section \ref{sec:densitydecompositions} when $R = 1$. Indeed, if $X = \RR^d$, $\mathcal{X}_R = (\ZZ / R)^d$, and $\mathcal{T}_R = \ZZ/R$, then a set $\mathcal{E} \subset (\ZZ / R)^d \times (\ZZ/R)$ has density type $(A_0,A_1)$ if and only if $R\; \mathcal{E} \subset \ZZ^d \times \ZZ$ has density type $(A_0,A_1)$.}
\end{equation}
%
To obtain $L^p$ bounds from these $L^2$ bounds, in the next section we will perform a \emph{density decomposition} to break up $\mathcal{X}_R \times \mathcal{T}_R$ into families of indices with controlled density, and then apply Proposition \ref{L2DensityProposition} on each subfamily to control \eqref{DAPOCJAPWOCJAWOIFJOI} via an interpolation.

\begin{prop} \label{L2DensityProposition}
    Fix $A \geq 1$. Consider a set $\mathcal{E} \subset \mathcal{X}_R \times \mathcal{T}_R$. For each $(x_0,t_0) \in \mathcal{E}$, consider $S\!_{x_0,t_0}: X \to \CC$ such that the family $\{ S\!_{x_0,t_0} \}$ satisfies the pointwise and quasi-orthogonality estimates of Proposition \ref{theMainEstimatesForWave}. Write $\mathcal{E} = \bigcup_{k = 0}^\infty \mathcal{E}_k$, where
    %
    \[ \mathcal{E}_0 = \{ (x,t) \in \mathcal{E}: 0 \leq |t| \leq 1/R \} \]
    %
    and for $k > 0$, define
    %
    \[ \mathcal{E}_k = \{ (x,t) \in \mathcal{E}: 2^{k-1} / R < |t| \leq 2^k / R \}. \]
    %
    Suppose that for each $k$, the set $\mathcal{E}_k$ has density type $(D,2^{k})$.
    %, i.e. so that for any set $B \subset \mathcal{X}_R \times \mathcal{T}_R$ with $\text{diam}(B) \leq 2^{k}/R$,
    %
%    \begin{equation}
%        \#( \mathcal{E}_k \cap B ) \leq R A\; \text{diam}(B).
%    \end{equation}
    %
    Then
    %
    \[ \Big\| \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} 2^{k \frac{d-1}{2}} {S\!}_{x_0,t_0} \Big\|_{L^2(X)}^2 \lesssim R^d \log(D) D^{\frac{2}{d-1}} \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k. \]
\end{prop}

%\begin{remark}
%    If $\| b_{t_0} \|_{L^1(I_0)} \sim 1$ and $\| u_{x_0} \|_{L^1(X)} \sim 1$, then locally constancy from the uncertainty principle and energy conservation of the wave equation tell us that morally,
    %
%    \begin{equation}
%        \| S\!_{x_0,t_0} \|_{L^2(X)}^2 \sim R^d t_0^{d-1}.
%    \end{equation}
    %
%    If $\| b_{t_0} \|_{L^1(I_0)} \sim 1$ and $\| u_{x_0} \|_{L^1(X)} \sim 1$ for all $(x_0,t_0) \in \mathcal{E}$, this means that Proposition \ref{L2DensityProposition} is morally equivalent to
    %
%    \begin{equation}
%        \Big\| \sum\nolimits_{(x_0,t_0) \in \mathcal{E}} {S\!}_{x_0,t_0} \Big\|_{L^2(X)} \lesssim \sqrt{\log(A)} A^{\frac{1}{d-1}} \left( \sum\nolimits_{(x_0,t_0) \in \mathcal{E}} \| {S\!}_{x_0,t_0} \|_{L^2(X)}^2 \right)^{1/2}.
%    \end{equation}
    %
%    Thus Proposition \ref{L2DensityProposition} is a kind of square root cancellation bound, albeit with an implicit constant which grows as the set $\mathcal{E}$ increases in density, a necessity given that the functions $\{ {S\!}_{x_0,t_0} \}$ are not almost-orthogonal to one another.
%\end{remark}

\begin{proof}
Write $F = \sum_k F_k$, where
%
\begin{equation}
    F_k = 2^{k \frac{d-1}{2}} \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} {S\!}_{x_0,t_0}.
\end{equation}
%
Our goal is to bound $\| F \|_{L^2(M)}$. Applying Cauchy-Schwarz, we have
%
\begin{equation} \label{loglossbound}
    \| F \|_{L^2(X)}^2 \leq \log(D) \left( \sum\nolimits_{k \leq \log(D)} \| F_k \|_{L^2(X)}^2 + \left\| \sum\nolimits_{k \geq \log(D)} F_k \right\|_{L^2(X)}^2 \right).
\end{equation}
%
Without loss of generality, increasing the implicit constant in the final result by applying the triangle inequality, we can assume that $\{ k : \mathcal{E}_k \neq \emptyset \}$ is $10$-separated, and that all values of $t$ with $(x,t) \in \mathcal{E}$ are positive. Thus if $F_k$ and $F_{k'}$ are both nonzero functions, then $k = k'$ or $|k - k'| \geq 10$.

%We consider an expansion
%
%\begin{equation} \label{AWIOJDIOWAJF190124214}
%    \left\| \sum\nolimits_{k \geq \log(A)} F_k \right\|_{L^2(M)}^2 = \sum\nolimits_{k,k' \geq \log(A)} \langle F_k, F_{k'} \rangle.
%\end{equation}
%
Let us estimate $\langle F_k, F_{k'} \rangle$ for $k \geq k' + 10$.
%the non-diagonal terms on the right hand side of \eqref{AWIOJDIOWAJF190124214}.
We write
%
\begin{equation}
    \langle F_k, F_{k'} \rangle = \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} \sum\nolimits_{(x_1,t_1) \in \mathcal{E}_{k'}} 2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}} \langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle.
\end{equation}
%
For each $(x_0,t_0) \in \mathcal{E}_k$, and each $k' \leq k - 10$, consider the set
%
\begin{equation}
    \mathcal{G}_0(x_0,t_0,k') = \{ (x_1,t_1) \in \mathcal{E}_{k'} : |(t_0 - t_1) - d_X^-(x_0,x_1)| \leq 2^{k' + 5} / R \},
\end{equation}
%
Also consider the sets of indices
%
\begin{equation}
    \mathcal{G}_l^+(x_0,t_0,k') = \{ (x_1,t_1) \in \mathcal{E}_{k'} : 2^{l} / R < |(t_0 - t_1) + d_X^+(x_0,x_1)| \leq 2^{l + 1} / R \}.
\end{equation}
%
and
%
\begin{equation}
    \mathcal{G}_l^-(x_0,t_0,k') = \{ (x_1,t_1) \in \mathcal{E}_{k'} : 2^{l} / R < |(t_0 - t_1) - d_X^-(x_0,x_1)| \leq 2^{l + 1} / R \}.
\end{equation}
%
If we set
%
\begin{equation}
    \mathcal{G}_0(x_0,t_0,k') = (\mathcal{G}_l^+(x_0,t_0,k') \cup \mathcal{G}_l^-(x_0,t_0,k'))
\end{equation}
%
and
%
\begin{equation}
\begin{split}
    \mathcal{G}_l(x_0,t_0,k') &= \Big( \mathcal{G}_l^+(x_0,t_0,k') \cup \mathcal{G}_l^-(x_0,t_0,k') \Big)\\
    &\quad\quad\quad\quad\quad\quad - \bigcup\nolimits_{r < l} \Big(\mathcal{G}_r^+(x_0,t_0,k') \cup \mathcal{G}_r^-(x_0,t_0,k') \Big).
\end{split}
\end{equation}
%
Then $\mathcal{E}_{k'}$ is covered by $\mathcal{G}_0(x_0,t_0,k')$ and $\mathcal{G}_l(x_0,t_0,k')$ for $k' + 5 \leq l \leq 10 \log R$. Define
%
\begin{equation}
    B_0(x_0,t_0,k') = \sum\nolimits_{(x_1,t_1) \in \mathcal{G}_0(x_0,t_0,k')} 2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}} |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle|,
\end{equation}
%
and
%
\begin{equation}
    B_l(x_0,t_0,k') = \sum\nolimits_{(x_1,t_1) \in \mathcal{G}_l(x_0,t_0,k')} 2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}} |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle|.
\end{equation}
%
We thus have
%
\begin{equation}
    \langle F_k, F_{k'} \rangle \leq \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} B_0(x_0,t_0,k') + \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} \sum\nolimits_{k' + 5 \leq l \leq 10 \log R} B_l(x_0,t_0,k').
\end{equation}
%
Using the density properties of $\mathcal{E}$, we can control the size of the index sets $\mathcal{G}_{\bullet}(x_0,t_0,k')$, and thus control the quantities $B_\bullet(x_0,t_0,k')$. The rapid decay of Proposition \ref{theMainEstimatesForWave} means that only $\mathcal{G}_0(x_0,t_0,k')$ needs to be estimated rather efficiently:
%
\begin{itemize}%[leftmargin=8mm]
    \item Start by bounding the quantities $B_0(x_0,t_0,k')$. If $(x_1,t_1) \in \mathcal{G}_0(x_0,t_0,k')$, then
    %
    \begin{equation}
        |d_X^-(x_0,x_1) - (t_0 - t_1)| \leq 2^{k'+5}/R,
    \end{equation}
    %
    Thus if we consider $\text{Ann}(x_0,t_0,k') = \{ x_1: |d_X^-(x_0,x_1) - t_0| \leq 2^{k'+8}/R \}$, which is a geodesic annulus of radius $\sim 2^k / R$ and thickness $O(2^{k'}/R)$, then
    %
    \begin{equation}
        \mathcal{G}_0(x_0,t_0,k') \subset \text{Ann}(x_0,t_0,k') \times [ 2^{k'}/R, 2^{k'+1}/R ].
    \end{equation}
    %
    The latter set is covered by $O(2^{(k-k')(d-1)})$ balls of radius $2^{k'}/R$, and so the density properties of $\mathcal{E}_{k'}$ implies that
    %
    \begin{equation} \label{G0Size}
        \#( \mathcal{G}_0(x_0,t_0,k') ) \lesssim D 2^{(k-k')(d-1)} 2^{k'}. 
    \end{equation}
    %
    Since $k \geq k' + 10$, for $(x_1,t_1) \in \mathcal{G}_0(x_0,t_0,k')$ we have $d_X(x_0,x_1) \gtrsim 2^k / R$ and so
    %
    \begin{equation} \label{InnerProductG0Size}
        \langle S\!_{x_0,t_0}, S\!_{x_1,t_1} \rangle \lesssim R^d 2^{-k \left( \frac{d-1}{2} \right)}.
    \end{equation}
    %
    But putting together \eqref{G0Size} and \eqref{InnerProductG0Size} gives that
    %
    \begin{align*}
        B_0(x_0,t_0,k') &\leq (2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}}) ( D 2^{(k-k')(d-1)} 2^{k'} )  ( R^d 2^{-k \left( \frac{d-1}{2} \right)} )\\
        &= D R^d 2^{k(d-1)} 2^{-k' \frac{d-3}{2}}.
    \end{align*}
    %
    Thus for each $k$, since $d \geq 4$,
    % d = 2: get an extra O( log k ) factor
    \begin{equation} \label{AAAlowbounds}
        \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} \sum\nolimits_{k' \in [\log(D), k - 10]} B_0(x_0,t_0,k') \lesssim R^{d} 2^{k (d-1)} \# \mathcal{E}_k.
    \end{equation}

    \item Next we bound $B_l(x_0,t_0,k')$ for $k' + 5 \leq l \leq k - 5$. The set $\mathcal{G}_l^+(x_0,t_0,k')$ is empty in this case. Thus
    %
    \begin{equation}
        \mathcal{G}_l(x_0,t_0,k') \subset ( \text{Ann} \cup \text{Ann}' ) \times [t_0 - 2^{k'} / R, t_0 + 2^{k'} / R],
    \end{equation}
    %
    where
    %
    \begin{equation}
        \text{Ann} = \{ x \in X: |d_X^-(x_0,x) - (t_0 - 2^{k'}) / R| \leq 100 \cdot 2^l / R \}
    \end{equation}
    %
    and
    %
    \begin{equation}
        \text{Ann}' = \{ x \in X: |d_X^-(x_0,x) - (t_0 + 2^{k'}) / R| \leq 100 \cdot 2^l / R \},
    \end{equation}
    %
    These are geodesic annuli of thickness $O(2^l / R)$ and radius $\sim 2^k$. Thus $\mathcal{G}_l(x_0,t_0,k')$ is covered by $O( 2^{(l-k')} 2^{(k-k')(d-1)} )$ balls of radius $2^{k'} / R$, and the density of $\mathcal{E}_{k'}$ implies that
    %
    \begin{equation}
        \#(\mathcal{G}_l(x_0,t_0,k')) \lesssim R D\; 2^{(l-k')} 2^{(k-k')(d-1)} 2^{k'} / R = D 2^{l} 2^{(k-k')(d-1)}.
    \end{equation}
    %
    For $(x_1,t_1) \in \mathcal{G}_l(x_0,t_0,k')$, $d_X(x_0,x_1) \sim 2^k / R$, and thus Proposition \ref{theMainEstimatesForWave} implies
    %
    \begin{equation}
        |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle| \lesssim R^d 2^{-k \frac{d-1}{2}} 2^{-lK}.
    \end{equation}
    %
    Thus for any $K \geq 0$,
    %
    \begin{equation}
    \begin{split}
        B_l(x_0,t_0,k') &\lesssim_K \Big( D 2^{l} 2^{(k-k')(d-1)} \Big)  R^{d} 2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}} \Big( 2^{-k \frac{d-1}{2}} 2^{-lK} \Big)\\
        &\lesssim D R^d 2^l 2^{k(d-1)} 2^{-k' \frac{d-1}{2}} 2^{-lK}.
    \end{split}
    \end{equation}
    %
    Picking $K > 1$, we conclude that
    % -d/2 + 1/2
    \begin{equation} \label{AAAlBoundSmall}
        \sum_{(x_0,t_0) \in \mathcal{E}_k} \sum_{k' \in [\log(D), k - 10]} \sum_{l \in [k' + 10, k - 5]} B_l(x_0,t_0,k') \lesssim R^{d} 2^{k (d-1)} \# \mathcal{E}_k.
    \end{equation}

    \item Finally, let's bound $B_l(x_0,t_0,k')$ for $k - 5 \leq l \leq 10 \log R$. If either $(x_1,t_1) \in \mathcal{G}_l^-(x_0,t_0,k')$ or $(x_1,t_1) \in \mathcal{G}_l^+(x_0,t_0,k')$, then $d_X(x_0,x_1) \lesssim 2^l / R$. So $\mathcal{G}_l(x_0,t_0,k')$ is covered by $O( 2^{(l-k')d} )$ balls of radius $2^{k'} / R$, and thus
    %
    \begin{equation}
        \#(\mathcal{G}_l(x_0,t_0,k')) \lesssim R D\; 2^{(l-k')d} (2^{k'} / R) = D 2^{(l-k')d} 2^{k'}.
    \end{equation}
    %
    For $(x_1,t_1) \in \mathcal{G}_l(x_0,t_0,k')$, we have no good control over $d_X(x_0,t_1)$ aside from the trivial estimate $d_X(x_0,x_1) \lesssim 1$. Thus Proposition \ref{theMainEstimatesForWave} yields a bound of the form
    %
    \begin{equation}
        |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle| \lesssim R^d 2^{-lK}.
    \end{equation}
    %
    Thus we conclude that
    %
    \begin{equation}
    \begin{split}
        B_l(x_0,t_0,k') &\lesssim_N R^{d} 2^{k \frac{d-1}{2}} 2^{k' \frac{d-1}{2}} \Big( D 2^{(l-k')d} 2^{k'} \Big) \Big( 2^{-lN} \Big)\\
        &= D R^d 2^{k \frac{d-1}{2}} 2^{-k' \frac{d-1}{2}} 2^{-lN}
    \end{split}
    \end{equation}
    %
    Picking $K > d$, we conclude that
    %
    \begin{equation} \label{AAAlBoundBig}
        \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} \sum\nolimits_{k' \in [\log(D), k - 10]} \sum\nolimits_{l \in [k+10,\log R]} B_l(x_0,t_0,k')  \lesssim R^d.
    \end{equation}
\end{itemize}
%
The three bounds \eqref{AAAlowbounds}, \eqref{AAAlBoundSmall} and \eqref{AAAlBoundBig} imply that
%
\begin{equation} \label{DADAOWIDJAWOIDJAWDaweq13412}
    \sum\nolimits_k \sum\nolimits_{k' \in [\log(D), k]} |\langle F_k, F_{k'} \rangle| \lesssim R^d \sum\nolimits_k 2^{k (d-1)} \# \mathcal{E}_k.
\end{equation}
%
In particular, combining \eqref{DADAOWIDJAWOIDJAWDaweq13412} with \eqref{loglossbound}, we have
%
\begin{equation} \label{DPOWADPAWKDPOWAKDOPWAK}
    \| F \|_{L^2(X)}^2 \lesssim \log(D) \left( \sum\nolimits_k \| F_k \|_{L^2(X)}^2 + R^d \sum\nolimits_k 2^{k (d-1)} \# \mathcal{E}_k \right).
\end{equation}
%
Next, consider some parameter $a$ to be determined later, and decompose the interval $[2^{k} / R, 2^{k+1} / R]$ into the disjoint union of length $D^a / R$ intervals of the form
%
\begin{equation}
    I_{k,\mu} = [ 2^{k} / R + (\mu - 1) D^a / R, 2^{k} / R + \mu D^a / R] \quad\text{for $1 \leq \mu \leq 2^k/D^a$}.
\end{equation}
%
We thus consider a further decomposition $\mathcal{E}_k = \bigcup \mathcal{E}_{k,\mu}$, where $F_k = \sum F_{k,\mu}$. As before, increasing the implicit constant in the Proposition, we may assume without loss of generality that the set $\{ \mu: \mathcal{E}_{k,\mu} \neq \emptyset \}$ is $10$-separated. We now estimate
%
\begin{equation}
    \sum\nolimits_{\mu \geq \mu' + 10} |\langle F_{k,\mu}, F_{k,\mu'} \rangle|.
\end{equation}
%
For $(x_0,t_0) \in \mathcal{E}_{k,\mu}$ and $l \geq 1$, define
%
\begin{equation}
    \mathcal{H}_l(x_0,t_0,\mu') = \Big\{ (x_1,t_1) \in \mathcal{E}_{k,\mu'} : \frac{2^l D^a}{2R} \leq \max(d_X(x_0,x_1), t_0 - t_1) \leq \frac{2^l D^a}{R} \Big\}.
\end{equation}
%
Then $\bigcup_{l \geq 1} \mathcal{H}_l(x_0,t_0,\mu')$ covers $\bigcup_{\mu \geq \mu' + 10} \mathcal{E}_{k,\mu'}$. Set
%
\begin{equation}
    B'_l(x_0,t_0,\mu') = \sum\nolimits_{(x_1,t_1) \in \mathcal{H}_l(x_0,t_0,\mu')} 2^{k(d-1)} |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle|.
\end{equation}
%
Then
%
\begin{equation}
    \langle F_{k,\mu}, F_{k,\mu'} \rangle \leq \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,\mu}} \sum\nolimits_l B'_l(x_0,t_0,\mu').
\end{equation}
%
We now bound the constants $B'_l$. Pick a constant $r$ such that $d_X \leq 2^r d_X^+$ and $d_X \leq 2^r d_X^-$. As in the estimates of the quantities $B_l$, the quantities where $l$ is large have negligible magnitude:
%
\begin{itemize}
    \item For $l \leq k - a \log_2 D + 10 r$, we have $2^l D^a / R \lesssim 2^k / R$. The set $\mathcal{H}_l(x_0,t_0,\mu')$ is covered by $O(1)$ balls of radius $2^l D^a / R$, and density properties imply
    %
    \begin{equation}
        \# \mathcal{H}_l(x_0,t_0,\mu') \lesssim (R D) (2^l D^a / R) = D^{a+1} 2^l
    \end{equation}
    %
    For $(x_1,t_1) \in \mathcal{H}_l(x_0,t_0,\mu')$, we claim that
    %
    \begin{equation}
        2^{k(d-1)} |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle| \lesssim R^{d} 2^{k(d-1)} (2^l D^a)^{- \frac{d-1}{2}}.
    \end{equation}
    %
    Indeed, for such tuples we have
    %
    \begin{equation}
        d_X(x_0,x_1) \gtrsim 2^l D^a / R \quad\text{or}\quad \min\nolimits_{\pm} |d_X^{\pm}(x_0,x_1) - (t_0 - t_1)| \gtrsim 2^l D^a / R,
    \end{equation}
    %
    and the estimate follows from Proposition \ref{theMainEstimatesForWave} in either case. Since $d \geq 4$, we conclude that
    %
    \begin{align} \label{BBBEquation}
    \begin{split}
        &\sum\nolimits_{l \in [1, k - a \log_2 D + 10]} B'_l(x_0,t_0,,\mu')\\
        &\quad\quad\quad\quad \lesssim \sum\nolimits_{l \in [1, k - a \log_2 D + 10]} R^{d} (2^{k(d-1)}) (2^l D^a)^{- \frac{d-1}{2}} (D^{a+1} 2^l)\\
        &\quad\quad\quad\quad \lesssim \sum\nolimits_{l \in [1, k - a \log_2 D + 10]} R^{d}  2^{k(d-1)} 2^{-l \frac{d-3}{2}} D^{1 - a \left( \frac{d-3}{2} \right)}\\
        &\quad\quad\quad\quad \lesssim R^{d} 2^{k(d-1)} D^{1 - a \left( \frac{d-3}{2} \right)}.
    \end{split}
    \end{align}

    \item For $l > k - a \log_2 D + 10 r$, a tuple $(x_1,t_1) \in \mathcal{E}_k$ lies in $\mathcal{H}_l(x_0,t_0,\mu')$ if and only if $2^l D^a / 2 R \leq d_X(x_0,x_1) \leq 2^l D^a / R$, since we always have
    %
    \begin{equation}
         t_0 - t_1 \leq 2^{k+1}/R < 2^{l+r} D^a / 8R.
    \end{equation}
    %
    and so $d_X(x_0,x_1) \geq 2^l D^a / 2R$. And so 
    %
    \[ |(t_0 - t_1) - d_X^-(x_0,x_1)| \geq 2^{-r} 2^l D^a / 2R - 2^{k+1} / R \geq 2^{-r} 2^l D^a / 4R. \]
    %
    Also $|(t_0 - t_1) + d_X^+(x_0,x_1)| \geq |d_X^+(x_0,x_1) \geq 2^{-r} 2^l D^a / 4R$. Thus we conclude from Proposition \ref{theMainEstimatesForWave} that
    %
    \begin{equation}
        2^{k(d-1)} |\langle {S\!}_{x_0,t_0}, {S\!}_{x_1,t_1} \rangle| \lesssim_K R^{d} 2^{k(d-1)} (2^l D^a)^{- K}.
    \end{equation}
    %
    Now $\mathcal{H}_l(x_0,t_0,\mu')$ is covered by $O( (2^{l-k} D^a)^d )$ balls of radius $2^k / R$, and the density properties of $\mathcal{E}_k$ thus imply that
    %
    \begin{equation}
        \#(\mathcal{H}_l(x_0,t_0,\mu')) \lesssim (RD) (2^{l-k} D^a)^d ( 2^k / R ) \lesssim D^{1 + ad} 2^{ld} 2^{-k(d-1)}.
    \end{equation}
    %
    Thus, picking $K > \max(d,1+ad)$, we conclude that
    %
    \begin{align} \label{BBB2}
    \begin{split}
        &\sum\nolimits_{l \geq k - a \log_2 D + 10} B'_l(x_0,t_0,\mu')\\
        &\quad \lesssim R^{d} \sum\nolimits_{l \geq k - a \log_2 D + 10} (2^{k(d-1)}) (2^l D^a)^{-M} D^{1 + ad} 2^{ld} 2^{-k(d-1)} \lesssim R^{d}.
    \end{split}
    \end{align}
    \end{itemize}
    %
    Combining \eqref{BBBEquation} and \eqref{BBB2}, and then summing over the tuples $(x_0,t_0) \in \mathcal{E}_{k,\mu}$, we conclude that
    %
    \begin{equation} \label{DOUIAWJDOIAWJVIO}
        \sum\nolimits_{\mu \geq \mu' + 10} |\langle F_{k,\mu}, F_{k,\mu'} \rangle| \lesssim R^{d} \left( 1 + 2^{k(d-1)} D^{1 - a \left( \frac{d-3}{2} \right)} \right) \# \mathcal{E}_{k,\mu}.
    \end{equation}
    %
    Now summing in $\mu$, \eqref{DOUIAWJDOIAWJVIO} implies that
    %
    \begin{equation} \label{DAOWDHAODWWID}
        \| F_k \|_{L^2(X)}^2 \lesssim \sum\nolimits_\mu \| F_{k,\mu} \|_{L^2(X)}^2 + R^{d} \left( 1 + 2^{k(d-1)} D^{1 - a \left( \frac{d-3}{2} \right)} \right) \# \mathcal{E}_k.
    \end{equation}
%
The functions in the sum defining $F_{k,\mu}$ are highly coupled, and it is difficult to use anything except Cauchy-Schwarz to break them apart. Since $\# ( \mathcal{T}_R \cap I_{k,\mu}) \sim D^a$, if we set $F_{k,\mu} = \sum_{t \in \mathcal{T}_R \cap I_{k,\mu}} F_{k,\mu,t}$, where
%
\begin{equation}
    F_{k,\mu,t} = \sum\nolimits_{(x_0,t) \in \mathcal{E}_{k,\mu}} 2^{k \frac{d-1}{2}} {S\!}_{x_0,t}.
\end{equation}
%
Then Cauchy-Schwarz implies that
%
\begin{equation} \label{IOJDAOIWDJAWOIJF}
    \| F_{k,\mu} \|_{L^2(X)}^2 \lesssim D^a \sum\nolimits_{t \in \mathcal{T}_R \cap I_{k,\mu}} \| F_{k,\mu,t} \|_{L^2(X)}^2.
\end{equation}
%
Since the elements of $\mathcal{X}_R$ are $1/R$ separated, the functions in the sum defining $F_{k,\mu,t}$ are quite orthogonal to one another; Proposition \ref{theMainEstimatesForWave} implies that for $x_0 \neq x_1$,
%
\begin{equation}
    |\langle {S\!}_{x_0,t}, {S\!}_{x_1,t} \rangle| \lesssim R^d ( R d_X(x_0,x_1) )^{-K} \quad\text{for all $K \geq 0$}.
\end{equation}
%
Thus
%
\begin{equation}
    \| F_{k,\mu,t} \|_{L^2(X)}^2 \lesssim R^{d} 2^{k(d-1)} \# (\mathcal{E}_k \cap (X \times \{ t \})).
\end{equation}
%
But this means that
%
\begin{equation} \label{eoqiejoiwjdoiaevjoa}
    D^a \sum\nolimits_{t \in \mathcal{T}_R \cap I_{k,\mu}} \| F_{k,\mu,t} \|_{L^2(X)}^2 \lesssim R^{d} 2^{k(d-1)} D^a \# \mathcal{E}_{k,\mu}.
\end{equation}
%
Thus \eqref{DAOWDHAODWWID}, \eqref{IOJDAOIWDJAWOIJF}, and \eqref{eoqiejoiwjdoiaevjoa} imply that
%
\begin{equation}
\begin{split}
    \| F_k \|_{L^2(X)}^2 &\lesssim \sum\nolimits_\mu \| F_{k,\mu} \|_{L^2(X)}^2 + R^{d} \left( 1 + 2^{k(d-1)} D^{1 - a \left( \frac{d-3}{2} \right)} \right) \# \mathcal{E}_k\\
    &\lesssim R^{d} \left( 2^{k(d-1)} D^a + (1 + 2^{k(d-1)} D^{1 - a \left( \frac{d-3}{2} \right)} \right) \# \mathcal{E}_k.
\end{split}
\end{equation}
% u^a = u^{1 - a(d-3)/2}
% a ( (d-1)/2 ) = 1
%
Optimizing by picking $a = 2 / (d-1)$ gives that
%
\begin{equation} \label{OICJOAIEVJAIOJFAOIJRIO}
    \| F_k \|_{L^2(X)}^2 \lesssim R^{d} 2^{k(d-1)} D^{\frac{2}{d-1}} \# \mathcal{E}_k.
\end{equation}
%
The proof is completed by combining \eqref{DPOWADPAWKDPOWAKDOPWAK} with \eqref{OICJOAIEVJAIOJFAOIJRIO}.
\end{proof}

Combining the $L^2$ analysis of Section \ref{regime1firstsection} with a density decomposition argument, we can now prove the following Lemma, which completes the analysis of the operator $T^I$ in Proposition \ref{TjbLemma}.

\begin{lemma} \label{regime1Lemma}
    Using the notation of Proposition \ref{TjbLemma}, let $T^I = \sum\nolimits_{t_0 \in \mathcal{T}_R} T^I_{t_0}$, where
    %
    \[ T^I_{t_0} = b_{t_0}^I(t) (e^{2 \pi i t P} \circ Q_R)\; dt. \]
    %
    Then for $1 \leq p < 2 (d-1) / (d+1)$,
    %
    \[ \| T^I u \|_{L^p(X)} \lesssim R^{-1/p'} \left( \sum\nolimits_{t_0 \in \mathcal{T}_R} \Big[ \| b^I_{t_0} \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \Big]^p \right)^{1/p} \| u \|_{L^p(X)}. \]
\end{lemma}

We prove Lemma \ref{regime1Lemma} via a \emph{density decomposition} argument, adapted from the methods of \cite{HeoandNazarovandSeeger}. Given a function $u: X \to \CC$, we use a partition of unity to write
%
\begin{equation}
    u = \sum\nolimits_{x_0 \in \mathcal{X}_R} u_{x_0},
\end{equation}
%
where $u_{x_0}$ is supported on $B(x_0,1/R)$, and
%
\begin{equation}
\begin{split}
    \left( \sum\nolimits_{x_0 \in \mathcal{X}_R} \| u_{x_0} \|_{L^1(X)}^p \right)^{1/p} &\lesssim R^{-d/p'} \left( \sum\nolimits_{x_0 \in \mathcal{X}_R} \| u_{x_0} \|_{L^p(X)}^p \right)^{1/p} \lesssim R^{-d/p'} \| u \|_{L^p(X)}.
\end{split}
\end{equation}
% L^p is H^p R^{-1}
% L^1 is H^p R^{-p}
Lemma \ref{regime1Lemma} follows from the following result.

\begin{lemma} \label{LpBoundLemma}
    Fix $u \in L^p(X)$, consider $2^{1-k}$ separated subsets $\mathcal{X}_k$ and $\mathcal{T}_k$, and a family of functions $\{ S\!_{x_0,t_0} : X \to \CC \}$  satisfying the pointwise and quasi-orthogonality estimates of Proposition \ref{theMainEstimatesForWave}. Then for any function $c: \mathcal{X}_R \times \mathcal{T}_R \to \CC$, and $1 < p < 2 (d-1) / (d+1)$,
    %
    \begin{align*}
    &\Bigg\| \sum\nolimits_{(x_0,t_0) \in \mathcal{X}_k \times \mathcal{T}_k} c(x_0,t_0) S\!_{x_0,t_0} \Big\|_{L^p(X)} \lesssim R^{d/p'} \left( \sum\nolimits_{(x_0,t_0) \in \mathcal{X}_k \times \mathcal{T}_k} \Big[ |c(x_0,t_0)| \langle R t_0 \rangle^{s} \Big]^p \right)^{1/p},
    \end{align*}
    %
    where $s = (d-1)(1/p - 1/2)$.
\end{lemma}

To see how Lemma \ref{LpBoundLemma} implies Lemma \ref{regime1Lemma}, given the setup of Lemma \ref{LpBoundLemma}, set 
%
\begin{equation}
    c(x_0,t_0) = \| b_{t_0} \|_{L^1(\RR)} \| u_{x_0} \|_{L^p(X)}
\end{equation}
%
for $x_0 \in \mathcal{X}_{a}$ and $t_0 \in \mathcal{T}_{b}$, and define
%
\begin{equation}
    S\!_{x_0,t_0} = \frac{1}{\| b_{t_0} \|_{L^1(\RR)} \| u_{x_0} \|_{L^1(X)}} \int b_{t_0}(t) ( e^{2 \pi i t P} \circ Q_R ) \{ u_{x_0} \}\; dt.
\end{equation}
%
Then Lemma \ref{LpBoundLemma} and H\"{o}lder's inequality implies that
%
\begin{equation}
\begin{split}
    \| T^I u \|_{L^p(X)} &\lesssim R^{d/p'} \left( \sum\nolimits_{(x_0,t_0)} \left[ \| b_{t_0}^I \|_{L^1(\RR)} \| u_{x_0} \|_{L^1(X)} \langle R t_0 \rangle^{s} \right]^p \right)^{1/p}\\
    &\lesssim R^{-1/p'} \left( \sum\nolimits_{t_0} \Big[ \| b_{t_0}^I \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \Big]^p \right)^{1/p}\left( \sum\nolimits_{x_0} \| u_{x_0} \|_{L^p(X)}^p \right)^{1/p}\\
    &\lesssim R^{-1/p'} \left( \sum\nolimits_{t_0} \Big[ \| b_{t_0}^I \|_{L^p(I_0)} \langle R t_0 \rangle^{s} \Big]^p \right)^{1/p} \| u \|_{L^p(X)}.
\end{split}
\end{equation}
% C = alpha(p) + d/p'
%   = (d+1)/2 - 1/p
%
Thus we have proved Lemma \ref{regime1Lemma}. We take the remainder of this section to prove Lemma \ref{LpBoundLemma} using a density decomposition argument.

\begin{proof}[Proof of Lemma \ref{LpBoundLemma}]

For $p = 1$, this inequality follows simply by applying the triangle inequality and applying the pointwise estimates of Proposition \ref{theMainEstimatesForWave}. By methods of interpolation, to prove the result for $p > 1$, we thus only need only prove a restricted strong type version of this inequality. In other words, we can restrict $c$ to be the indicator function of a set $\mathcal{E} \subset \mathcal{X}_R \times \mathcal{T}_R$. Write $\mathcal{E} = \bigcup_{k \geq 0} \mathcal{E}_k$, where
%
\begin{equation}
    \mathcal{E}_0 = \{ (x,t) \in \mathcal{E} : |t| \leq 1/R \}
\end{equation}
%
and for $k > 0$, let
%
\begin{equation}
    \mathcal{E}_k = \{ (x,t) \in \mathcal{E} : 2^{k-1} / R < |t| \leq 2^{k} / R \}.
\end{equation}
%
Write
%
\begin{equation}
    F_k = \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k} 2^{k \left( \frac{d-1}{2} \right)} S\!_{x_0,t_0}.
\end{equation}
%
Our proof will be completed if we can show that
%
\begin{equation} \label{oDOIAWJCVOIEJOIJER1312s}
    \Big\| \sum\nolimits_k F_k \Big\|_{L^p(X)} \lesssim R^{d ( 1 - 1/p )} \Big( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \Big)^{1/p}.
\end{equation}
%
To prove \eqref{oDOIAWJCVOIEJOIJER1312s}, we perform a density decomposition on the sets $\{ \mathcal{E}_k \}$. Applying a rescaled version of Lemma \ref{DecompositionTheorem}, we can obtain a disjoint union
%
\begin{equation}
    \mathcal{E}_k = \bigcup\nolimits_{u \geq 0} \mathcal{E}_k(u),
\end{equation}
%
where $\mathcal{E}_k(u)$ has density type $(R 2^{u}, 2^{k} / 100 R)$, and is covered by $B_{k,u,1}^*,\dots,B_{k,u,N_{k,u}}^*$, where the family $\{ B_{k,u,n} \}$ are a family of disjoint balls, each of radius at most $2^{k} / 100 R$ such that
%
\begin{equation}
    \sum\nolimits_n \text{rad}(B_{k,u,n}) \leq 2^{-u} / R \# \mathcal{E}_k.
\end{equation}
%
and such that $\mathcal{E}_k(u)$ is covered by the balls $\{ B_{k,u,n}^* \}$, where, for a ball $B$, $B^*$ denotes the ball with the same center as $B$, but 5 times the radius. Now write
%
\begin{equation}
    F_{k,u} = \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k(u)} 2^{k \left( \frac{d-1}{2} \right)} S\!_{x_0,t_0}.
\end{equation}
%
We can apply Lemma \ref{L2DensityProposition} of the last section to $\{ \mathcal{E}_k(u) \}$, which implies that
%
\begin{equation} \label{DOIWAJOIAJVOIWAJFOIWF}
\begin{split}
    \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^2(X)} \lesssim R^{d/2} \left( u^{1/2} 2^{u \left( \frac{1}{d-1} \right)} \right) \left( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/2}.
\end{split}
\end{equation}
%
Let $(y_{k,u,n}, t_{k,u,n})$ denote the center of $B_{k,u,n}$. Then the functions
%
\begin{equation}
    \sum\nolimits_{(x_0,t_0) \in [B_{k,u,n} \cap \mathcal{E}_k(u)]} S\!_{x_0,t_0}
\end{equation}
%
have mass concentrated on the geodesic annulus $\text{Ann}_{k,u,n} \subset X$ with center $y_{k,u,n}$, with radius $t_{k,u,n} \sim 2^{k} / R$, and with thickness $5\; \text{rad}(B_{k,u,n})$. Thus
%
\begin{equation}
    \sum\nolimits_n |\text{Ann}_{k,u,n}| \lesssim \sum\nolimits_{n} (2^{k} / R)^{d-1} \text{rad}(B_{k,u,n}) \leq (2^{k}/R)^{d-1} R^{-1} 2^{-u} \# \mathcal{E}_k.
\end{equation}
%
If we set $\Lambda_u = \bigcup_k \bigcup_n \text{Ann}_{k,u,n}$, then
%
\begin{equation}
    |\Lambda_u| \lesssim R^{-d} 2^{-u} \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k
\end{equation}
%
Since $1/p - 1/2 > 1/(d-1)$, so that $s > 1$, H\"{o}lder's inequality implies that
%
\begin{equation}
\begin{split}
    \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^p(\Lambda_u)} &\lesssim |\Lambda_u|^{1/p - 1/2} \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^2(\Lambda_{k,u})}\\
    &\lesssim \left( R^{-d} 2^{-u} \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p - 1/2}\\
    &\quad\quad\quad\quad \left( R^{d} \left( u 2^{u \left( \frac{2}{d-1} \right)} \right) \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/2}\\
    &= R^{d(1-1/p)} \left( u^{1/2} 2^{-u \left( \frac{s - 1}{d - 1} \right)}  \right) \left( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p}\\
    &\lesssim R^{d/p'} 2^{-u \varepsilon} \left( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p}
\end{split}
\end{equation}
%
for some suitable small $\varepsilon > 0$. For each $(x_0,t_0) \in \mathcal{E}_{k,a,b}(u) \cap B_{k,u,n}$, using the poitnwise bounds of Proposition \ref{theMainEstimatesForWave} we calculate that
%
%\begin{align*}
%        \| 2^{-(l+r)} f_{x_0,t_0} \|_{L^q(\text{Ann}_n^c)}^q &= 2^{jdq} \int_{\text{Ann}_j^c} \langle 2^j d_X(x,x_0) \rangle^{- q \left( \frac{d-1}{2} \right)} \langle 2^j |t_0 - d_X(x,x_0)| \rangle^{-qM}\; dx \\
%        &\lesssim 2^{jq \left( \frac{d+1}{2} - M \right)} \int_{5\; \text{rad}(B_n)}^{O(1)} (2^{k-j} + s)^{(d-1) - q \left( \frac{d-1}{2} \right)} s^{-qM}\; ds\\
%    &\lesssim 2^{k(d-1)(1-q/2)} 2^{j[ q \left( d - M \right) - (d-1) ]} \text{rad}(B_n)^{1 - qM}.
%\end{align*}
\begin{equation}
\begin{split}
        \| S\!_{x_0,t_0} \|_{L^1(\Lambda(u)^c)} &= R^{d} \int_{\text{Ann}_R^c} \langle R d_X(x,x_0) \rangle^{- \left( \frac{d-1}{2} \right)} \langle R |t_0 - d_X(x,x_0)| \rangle^{-M}\; dx\\
        &\lesssim R^{ \left( \frac{d+1}{2} - M \right)} \int_{5\; \text{rad}(B_{k,u,n})}^{O(1)} ( t_{k,u,n} + s)^{\left( \frac{d-1}{2} \right)} s^{-M}\; ds\\
        &\lesssim R^{ \left( \frac{d+1}{2} - M \right)} \text{rad}(B_{k,u,n})^{1-M} t_{k,u,n}^{\left( \frac{d-1}{2} \right)}\\
        &\lesssim 2^{k \left( \frac{d-1}{2} \right)} (R \text{rad}(B_{k,u,n}))^{1 - M}.
\end{split}
\end{equation}
%
Thus
%
%\[ \| 2^{k \left( \frac{d-1}{2} \right)} 2^{-(l+r)} f_{x_0,t_0} \|_{L^q(\text{Ann}_n^c)} \lesssim 2^{k \left( \frac{d-1}{q} \right) } 2^{jd/q'} (2^j \text{rad}(B_n))^{1/q - M} \]\
\begin{equation}
    \|  S\!_{x_0,t_0} \|_{L^1(\text{Ann}_n^c)} \lesssim 2^{k \big( \frac{d-1}{2} \big)} (R \text{rad}(B_{k,u,n}))^{1 - M}
\end{equation}
%
% 2^{(k-j)[-p(d-1)/2]} rad(B_n)^{d-pM}
%      >> 2^{(k-j)( -p(d-1)/2 + d - pM )}
%
% 2^{(k-j)( d - p(d-1)/2 - pM )}
% 
%
Because the set of points in $\mathcal{E}_k$ is $1/R$ separated, there are at most $O( (R \text{rad}(B_{k,u,n}))^{d+1} )$ points in $\mathcal{E}_k(u) \cap B_{k,u,n}$, and so the triangle inequality implies that
% \mathcal{E}_{k,l,r} - \widehat{\mathcal{E}}_{k,l,r} = \bigcup_{l,r} 
%\begin{align*}
%    &\left\| \sum\nolimits_{l,r} \sum\nolimits_{(x_0,t_0) \in (\mathcal{E}_{k,l,r} - \widehat{\mathcal{E}}_{k,l,r}) \cap B_n} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(l+r)} f_{x_0,t_0} \right\|_{L^q(\text{Ann}_n^c)}\\
%    &\quad\quad \lesssim 2^{k \left( \frac{d-1}{q} \right)} 2^{jd/q'} (2^j \text{rad}(B_n))^{d + 1 + 1/q - M}
%\end{align*}
\begin{equation}
\begin{split}
    &\Big\| \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k(u) \cap B_{k,u,n}} S\!_{x_0,t_0} \Big\|_{L^1(\Lambda(u)^c)} \lesssim 2^{k \big( \frac{d - 1}{2} \big)} (R \text{rad}(B_{k,u,n}))^{d + 2 - M}.
\end{split}
\end{equation}
%
Since $\# \mathcal{E}_k \cap B_{k,u,n} \geq R 2^{u}\ \text{rad}(B_{k,u,n})$, and $\mathcal{E}_k$ is $1/R$ discretized, we must have
%
\begin{equation}
    \text{rad}(B_{k,u,n}) \geq (2^u / 2^d)^{\frac{1}{d-1}}\; 1/R.
\end{equation}
%
Thus
%
% 2^{jd(p-1)}
%
\begin{equation}
\begin{split}
    \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^1(\Lambda(u)^c)} &\lesssim_X \sum\nolimits_k \sum\nolimits_n 2^{k (d-1)} (R \text{rad}(B_{k,u,n}))^{d + 2 - M}\\
    &\lesssim \sum\nolimits_k 2^{k(d-1)} \Big( R \min\nolimits_n \text{rad}(B_{k,u,n}) \Big)^{d + 1 - M} \left( \sum\nolimits_n R \text{rad}(B_{k,u,n}) \right) \\
    &\lesssim \sum\nolimits_k 2^{k (d-1)} 2^{u \left( \frac{d+1-M}{d-1} \right)} \left( 2^{-u} \# \mathcal{E}_k \right)\\
    &\lesssim 2^{u \left( \frac{2-M}{d-1} \right)} \sum\nolimits_k 2^{k (d-1)} \# \mathcal{E}_k
\end{split}
\end{equation}
%
Picking $M > 2 + (1/p')(1/p - 1/2)^{-1}$, and interpolating with the bounds on $\| \sum_k F_{k,u} \|_{L^2(X)}$ yields that
%
\begin{equation}
\begin{split}
    \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^p(\Lambda(u)^c)} &\lesssim \left( 2^{u \left( \frac{2-M}{d-1} \right)} \right)^{2/p - 1} \left( R^{d/2} \left( u^{1/2} 2^{u \left( \frac{1}{d-1} \right)} \right) \right)^{2/p'} \left( \sum 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p} \\
    &\lesssim 2^{-u \varepsilon} R^{d/p'} \sum\nolimits_k \left( \sum 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p}.
\end{split}
\end{equation}
%
So now we know
%
\begin{equation}
    \Big\| \sum\nolimits_k F_{k,u} \Big\|_{L^p(X)} \lesssim R^{d(1-1/p)} 2^{- u \varepsilon} \left( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p}.
\end{equation}
%
The exponential decay in $u$ allows us to sum in $u$ to obtain that
%
\begin{equation}
    \Big\| \sum\nolimits_u \sum\nolimits_k F_{k,u} \Big\|_{L^p(X)} \lesssim R^{d/p'} \left( \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k \right)^{1/p}.
\end{equation}
%
This is precisely the bound we were required to prove.
\end{proof}



\begin{comment}



which, within the range $p < 2(d-1)/(d+1)$ we are considering, and since we are assuming $\lambda \gtrsim_d 2^{jd}$, satisfies
%
\begin{align*}
        \sum_n |\text{Ann}_n| &\lesssim \log(\lambda/2^{jd})^{(2-p) \left( \frac{d-1}{2} \right)} (2^{k-j})^{d-1} 2^{-j} \left( 2^{jd} / \lambda \right)^{(2-p) \left( \frac{d-1}{2} \right)} \# \mathcal{E}_k\\
        &= \log(\lambda/2^{jd})^{(2-p) \left( \frac{d-1}{2} \right)} (\lambda/2^{jd})^{p \left( \frac{d+1}{2} \right) - (d-1)} 2^{jd(p-1)} \Big( 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{-p}\\
        &\lesssim 2^{jd(p-1)} \Big( 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{-p}.
\end{align*}
%
The last inequality uses the fact that for any $\varepsilon, \delta > 0$, and $x \geq 10^{d+1}$,
%
\[ \log(x)^\delta x^{-\varepsilon} \lesssim_{\delta,\varepsilon} 1. \]


% 2^{k-j} in diameter
% So contained in a ball with radius 2^{k-j}
%   Place balls of radius 1/20 in this ball. Then the union of these balls is
%   contained in a ball of radius 21/20. Therefore there are at most 21^d
%   such balls
% On each of these balls, << 2^{j+u} rad(B) / 20


% p / p' = p (1 - 1/p) = p - 1
% When p = 1 the inequality says
% Sum_k 2^{k (d-1)/2} |S\!_{x_0,t_0}|_{L^1} << R^{-1} sum_k 2^{k(d-1)} #(E_k)
%
% d_g(x,x_0) ~ 2^k / R
%
% Has height R^{d-1} 2^{-k (d-1)/2}
%
% on an annulus of thickness 1/R, and radius 2^k/R
%
% So has L^1 norm R^{-1} 2^{k(d-1)/2}
%
% SO WE DO GET THE p = 1 INEQUALITY!
%
% So for weak type estimate, by interpolation,
% we only have to consider large lambda superlevel sets
%
% LOW DENSITY PART: DEALT WITH USING L2 ESTIMATE
% HIGH DENSITY PART: Since lambda is large,
%           can use essential support of function.
%



This is equivalent to showing that for any $\lambda > 0$,
%
\begin{align} \label{FSumLPInfBound}
\begin{split}
    &\bigg| \Big\{ x: \Big| \sum\nolimits_{a,b}  \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0}(x) \Big| \geq \lambda \Big\} \bigg|\\
    &\quad\quad\quad \lesssim  2^{j d (p - 1)} \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-p}.
\end{split}
\end{align}
%
Applying Markov's inequality, as well as the $p = 1$ inequality, we find that
%
\[ \bigg| \Big\{ x: \Big|\sum\nolimits_{a,b} \sum\nolimits_{k} \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0}(x) \Big| \geq \lambda \Big\} \bigg| \lesssim \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-1} \]
%
We have
%
\[ \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-1} \lesssim 2^{jd(p-1)} \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-p} \]
% lambda^{p-1} << 2^{jd(p-1)}
for $\lambda \leq 10^{d+2} 2^{jd}$, so we may assume $\lambda \geq 10^{d+2} 2^{jd}$ in what follows. We then employ the method of density decompositions introduced in \cite{HeoandNazarovandSeeger}. Fix a quantity $A \geq 10^{d+1}$, to be chosen later. For each $k$, we consider the collection $\mathcal{B}_k$ of all balls $B$ with radius at most $2^{k-j} / 10$ such that $\# \mathcal{E}_k \cap B \geq (2^j A) \text{rad}(B)$. Applying the Vitali covering lemma, we can find a disjoint family of balls $\{ B_1, \dots, B_N \}$ in $\mathcal{B}_k$ such that the balls $\{ B_1^*, \dots, B_N^* \}$ obtained by dilating the balls by 5 cover $\bigcup \mathcal{B}_k(\lambda)$. Then
%
\[ \sum_n \text{rad}(B_n) \leq 2^{-j} A^{-1} \# \mathcal{E}_k. \]
%
Then the set $\widehat{\mathcal{E}}_k = \mathcal{E}_k - \bigcup \mathcal{B}_k(\lambda)$ has density type $(10^d 2^j A, 2^{k-j})$. Thus we can apply Lemma \ref{L2DensityProposition} of the last section, which implies that, with ${S\!}_{x_0,t_0} = 2^{-(a+b)} f_{x_0,t_0}$ for $(x_0,t_0) \in \mathcal{E}_{k,a,b}$,
%
\[ \Big\| \sum\nolimits_{a,b} \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \widehat{\mathcal{E}}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0} \Big\|_{L^2(M)}^2 \lesssim 2^{jd} \log(A) A^{\frac{2}{d-1}} \sum_k 2^{k(d-1)} \# \mathcal{E}_k. \]
%2^{j(d-2)} \log(A) A^{\frac{2}{d-1}} \sum_k 2^{k(d-1)} \# \mathcal{E}_k. \]
%
Applying Chebyshev's inequality, we conclude that
%
\begin{align*}
    &\bigg| \Big\{ x: \Big|\sum\nolimits_{a,b} \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \widehat{\mathcal{E}}_k} 2^{k \frac{d-1}{2}} 2^{-(a+b)} f_{x_0,t_0}(x)\Big| \geq \lambda / 2 \Big\} \bigg|\\
    &\quad\quad\quad \lesssim 2^{jd} \log(A) A^{\frac{2}{d-1}} \Big( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{-2}.
\end{align*}
% 
% TODO: Bound A^s log(A) by some power of A for large A.
%
% 2^{jd} A^{2/(d-1)} / lambda^2 << 2^{jd(p-1)} / lambda^p
% A << (lambda / 2^{jd})^{(2-p)(d-1)/2}
%
% A^{2/(d-1) + log log A} << (L/2^{jd})^{2-p}
% If A <= (L/2^{jd})^{(2-p)(d-1)/2}
% then log log A <= C_{p,d} + log log (L / 2^{jd})
% A^{2/(d-1) + C_{p,d} + log log (L / 2^{jd})} <= (L / 2^{jd})^{2-p}
% (2/(d-1) + C_{p,d} + log log (L / 2^{jd})) log A <= (2-p) log (L / 2^{jd})
% log A <= (2-p) log (L / 2^{jd}) / (C + log log(L / 2^{jd}))
% A = (L / 2^{jd})^{(2-p) / (C + log log (L / 2^{jd})) }
% So if L = 2^{2^N} 2^{jd},
% A = 2^{(2^N - jd)(2-p)/(C + N)}
%
Choose
%
\[ A = \log(\lambda / 2^{jd})^{\left( \frac{d-1}{2} \right)} \left( \lambda / 2^{jd} \right)^{(2-p) \left( \frac{d-1}{2} \right)}, \]
%
so that
%
\[ (\log A)^{\left( \frac{d-1}{2} \right)} A \lesssim (\lambda / 2^{jd})^{(2-p) \left( \frac{d-1}{2} \right)}. \]
%
Then
%
\begin{align} \label{ChebyshevFirstBound}
\begin{split}
    &\bigg| \bigg\{ x: \bigg|\sum_{a,b} \sum_k \sum_{(x_0,t_0) \in \widehat{\mathcal{E}}_k} 2^{k \frac{d-1}{2}} 2^{-(a+b)} f_{x_0,t_0}(x)\bigg| \geq \lambda / 2 \bigg\} \bigg|\\
    &\quad\quad\quad \lesssim 2^{jd(p-1)} \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-p}.
\end{split}
\end{align}
%
\eqref{ChebyshevFirstBound} gives a good enough bound for $\widehat{\mathcal{E}}_k$. Conversely, we exploit the clustering of the sets $\mathcal{E}_k - \widehat{\mathcal{E}}_k$ to bound
%
\[ \bigg| \Big\{ x: \Big| \sum\nolimits_{a,b} \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_k - \widehat{\mathcal{E}}_k} 2^{k \frac{d-1}{2}} 2^{-(a+b)} f_{x_0,t_0}(x) \Big| \geq \lambda / 2 \Big\} \bigg| \]
%
We have found balls $B_1^*, \dots, B_N^*$, each with radius at most $2^{k-j} / 10$, such that
%
\[ \sum \text{rad}(B_n) \leq 2^{-j} A^{-1} \# \mathcal{E}_k. \]
%
Let $(y_n,r_n)$ denote the center of the ball $B_n$. Then the function
%
\[ \sum\nolimits_{(x_0,t_0) \in B_n \cap (\mathcal{E}_k - \widehat{\mathcal{E}}_k)} 2^{-(a+b)} f_{x_0,t_0} \]
%
has mass concentrated on the geodesic annulus $\text{Ann}_n \subset M$ centred at $y_n$, with radius $r_n \sim 2^{k-j}$ and thickness $5\; \text{rad}(B_n)$. But we then calculate that
%
\[ \sum_n |\text{Ann}_n| \lesssim \sum_n (2^{k-j})^{d-1} \text{rad}(B_n) \leq (2^{k-j})^{d-1} 2^{-j} A^{-1} \# \mathcal{E}_k \]
%
which, within the range $p < 2(d-1)/(d+1)$ we are considering, and since we are assuming $\lambda \gtrsim_d 2^{jd}$, satisfies
%
\begin{align*}
        \sum_n |\text{Ann}_n| &\lesssim \log(\lambda/2^{jd})^{(2-p) \left( \frac{d-1}{2} \right)} (2^{k-j})^{d-1} 2^{-j} \left( 2^{jd} / \lambda \right)^{(2-p) \left( \frac{d-1}{2} \right)} \# \mathcal{E}_k\\
        &= \log(\lambda/2^{jd})^{(2-p) \left( \frac{d-1}{2} \right)} (\lambda/2^{jd})^{p \left( \frac{d+1}{2} \right) - (d-1)} 2^{jd(p-1)} \Big( 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{-p}\\
        &\lesssim 2^{jd(p-1)} \Big( 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{-p}.
\end{align*}
%
The last inequality uses the fact that for any $\varepsilon, \delta > 0$, and $x \geq 10^{d+1}$,
%
\[ \log(x)^\delta x^{-\varepsilon} \lesssim_{\delta,\varepsilon} 1. \]
% p < 2(d-1)/(d+1)
% p - (2 - p)(d-1)/2 = 2(d-1)/(d+1) - (2(d-1)/(d+1))
%
%\begin{align*}
%     2^{-jd} & \left( \frac{\lambda^{2-p}}{2^{j(d+1)(1 - p/2)}} \right)^{- \frac{d-1}{2}} ( 2^{k(d-1)} \# \mathcal{E}_k )\\
%     &\quad\quad = 2^{j \left[ \left( \frac{d-1}{2} \right) (d+1)(1 - p/2) - d \right]} \lambda^{p - (2-p) \left( \frac{d-1}{2} \right)} ( 2^{k(d-1)} \# \mathcal{E}_k ) \lambda^{-p}\\
%     &\quad\quad = 2^{j \left[ \left( \frac{d-1}{2} \right) (d+1)(1 - p/2) - d \right]} \lambda^{p \left( \frac{d+1}{2} \right) - (d-1)} ( 2^{k(d-1)} \# \mathcal{E}_k ) \lambda^{-p}\\
%     &\quad\quad \leq 2^{j \left[ \left( \frac{d-1}{2} \right) (d+1)(1 - p/2) - d + \left\{ p \left( \frac{d+1}{2} \right) - (d-1) \right\} \left( \frac{d+1}{2} \right) \right]}\\
%     &\quad\quad = 2^{j \left[ - d + (p/4) [ d^2 + d + 2 ] \right]} ( 2^{k(d-1)} \# \mathcal{E}_k ) \lambda^{-p}\\
%     &\quad\quad = 2^{j \left[ p \left( \frac{d+1}{2} \right) - 1 \right]} 2^{j(d-1)[ pd/4 - 1]}
%\end{align*}
% - d
%
%\begin{align*}
%    (2^{k-j})^{d-1} 2^{-j} &  \left( \frac{\lambda^{2-p}}{2^{j \left[ (d-1) - p \left( \frac{d+1}{2} \right) \right]}} \right)^{- \frac{d-1}{2}} \# \mathcal{E}_k\\
%    &= 2^{j \left[ \frac{d^2 - 4d + 1}{2} - p  \left( \frac{d^2 - 1}{4} \right) \right]}\; \lambda^{p \left( \frac{d+1}{2} \right) - (d-1)}  \; 2^{k(d-1)} \# \mathcal{E}_k\; \lambda^{-p}\\
%    &\lesssim 2^{j \left[ \frac{d^2 - 4d + 1}{2} - p  \left( \frac{d^2 - 1}{4} \right) \right]} 2^{j \left[ p \left( \frac{d^2+2d + 1}{4} \right) - \left( \frac{d^2 - 1}{2} \right) \right]}  \; \left( 2^{k(d-1)} \# \mathcal{E}_k \right)\; \lambda^{-p}\\
%    &= 2^{j \left[ p \left( \frac{d + 1}{2} \right) - (2d - 1) \right]}   \; \left( 2^{k(d-1)} \# \mathcal{E}_k \right)\; \lambda^{-p}\\
%    &\lesssim 2^{j \left[ p \left( \frac{d+1}{2} \right) - 1 \right]}   \; \left( 2^{k(d-1)} \# \mathcal{E}_k \right)\; \lambda^{-p}
%\end{align*}
%
%\textcolor{red}{TODO: LAST INEQUALITY SEEMS SUSPICIOUSLY LOOSE.}
%
Defining $\text{Bad}_k = \bigcup_n \text{Ann}_n$, and $\text{Bad} = \bigcup_k \text{Bad}_k$, we have
%
\begin{align} \label{BadSet}
    |\text{Bad}| \lesssim 2^{jd (p-1)} \sum\nolimits_k 2^{k(d-1)} \# \mathcal{E}_k\; \lambda^{-p}.
\end{align}
%
This is an exceptional set with size appropriate for the proof of the $L^{p,\infty}$ bound. All that remains is to account for the negligible error terms associated with the functions $f_{x_0,t_0}$, i.e. their behaviour on $\text{Bad}^c$. For each $(x_0,t_0) \in (\mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}) \cap B_n$, we calculate using the pointwise bounds for the functions $\{ f_{x_0,t_0} \}$ that
%
%\begin{align*}
%        \| 2^{-(l+r)} f_{x_0,t_0} \|_{L^q(\text{Ann}_n^c)}^q &= 2^{jdq} \int_{\text{Ann}_j^c} \langle 2^j d_g(x,x_0) \rangle^{- q \left( \frac{d-1}{2} \right)} \langle 2^j |t_0 - d_g(x,x_0)| \rangle^{-qM}\; dx \\
%        &\lesssim 2^{jq \left( \frac{d+1}{2} - M \right)} \int_{5\; \text{rad}(B_n)}^{O(1)} (2^{k-j} + s)^{(d-1) - q \left( \frac{d-1}{2} \right)} s^{-qM}\; ds\\
%    &\lesssim 2^{k(d-1)(1-q/2)} 2^{j[ q \left( d - M \right) - (d-1) ]} \text{rad}(B_n)^{1 - qM}.
%\end{align*}
\begin{align*}
        \| 2^{-(a+b)} f_{x_0,t_0} \|_{L^1(\text{Ann}_n^c)} &= 2^{jd} \int_{\text{Ann}_j^c} \langle 2^j d_g(x,x_0) \rangle^{- \left( \frac{d-1}{2} \right)} \langle 2^j |t_0 - d_g(x,x_0)| \rangle^{-M}\; dx \\
        &\lesssim 2^{j \left( \frac{d+1}{2} - M \right)} \int_{5\; \text{rad}(B_n)}^{O(1)} (2^{k-j} + s)^{\left( \frac{d-1}{2} \right)} s^{-M}\; ds\\
    &\lesssim 2^{k \left( \frac{d-1}{2} \right)} 2^{j(1 - M)} \text{rad}(B_n)^{1 - M}.
\end{align*}
%
Thus
%
%\[ \| 2^{k \left( \frac{d-1}{2} \right)} 2^{-(l+r)} f_{x_0,t_0} \|_{L^q(\text{Ann}_n^c)} \lesssim 2^{k \left( \frac{d-1}{q} \right) } 2^{jd/q'} (2^j \text{rad}(B_n))^{1/q - M} \]
\[ \| 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0} \|_{L^1(\text{Ann}_n^c)} \lesssim 2^{k \left( d - 1 \right) } (2^j \text{rad}(B_n))^{1 - M} \]
%
% 2^{(k-j)[-p(d-1)/2]} rad(B_n)^{d-pM}
%      >> 2^{(k-j)( -p(d-1)/2 + d - pM )}
%
% 2^{(k-j)( d - p(d-1)/2 - pM )}
% 
%
Because the set of points in $\mathcal{E}_k$ is $2^{-j}$ separated, there are at most $O( (2^j \text{rad}(B_n))^{d+1} )$ points in $(\mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}) \cap B_n$, and so the triangle inequality implies that
% \mathcal{E}_{k,l,r} - \widehat{\mathcal{E}}_{k,l,r} = \bigcup_{l,r} 
%\begin{align*}
%    &\left\| \sum\nolimits_{l,r} \sum\nolimits_{(x_0,t_0) \in (\mathcal{E}_{k,l,r} - \widehat{\mathcal{E}}_{k,l,r}) \cap B_n} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(l+r)} f_{x_0,t_0} \right\|_{L^q(\text{Ann}_n^c)}\\
%    &\quad\quad \lesssim 2^{k \left( \frac{d-1}{q} \right)} 2^{jd/q'} (2^j \text{rad}(B_n))^{d + 1 + 1/q - M}
%\end{align*}
\begin{align*}
    &\Big\| \sum\nolimits_{a,b} \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0} \Big\|_{L^1(\text{Ann}_n^c)} \lesssim 2^{k \left( d - 1 \right)} (2^j \text{rad}(B_n))^{d + 2 - M}.
\end{align*}
%
Since $\# \mathcal{E}_k \cap B_n \geq 2^j A\ \text{rad}(B_n)$, and because $\mathcal{E}_k$ is $2^{-j}$ discretized, we must have
%
\[ \text{rad}(B_n) \geq (A / 2^d)^{\frac{1}{d-1}}\; 2^{-j}. \]
%
%
%
% CALCULATIONS q = 1:
%
%   L^1 norm for fixed ball is 2^{k(d-1)} ( 2^j \text{rad}(B_n) )^{d + 2 - M}
%       Summing over, using the fact that sum 2^j rad(B_n) <= A^{-1} #(E_k)
%       and that 2^j rad(B_n) >> A^{1/(d-1)}
%   
%       2^{k(d-1)} A^{-1} (2^j rad(B_n))^{d + 1 - M} #(E_k)
%       2^{k(d-1)} A^{-(M - 2)/(d-1)} #(E_k)
%       A^{-(M-2)/(d-1)} 2^{k(d-1)} #(E_k)
%       (L/2^{jd)}^{-(2-p)(M-2)/2}) 2^{k(d-1)} #(E_k)
%           Choosing M Appropriately
%       L^{1-p} 2^{jd(p-1)} 2^{k(d-1)} #(E_k)
%
%       But this means the points above L have measure
%
%       2^{jd(p-1)} 2^{k(d-1)} #(E_k) L^{-p}
%
%       Consider x_n
%
%       With 2^{u eps} <= x_n <= 2^k
%
%       And sum x_n <= 2^{-u} A

Suppose we pick $M$ to be any integer larger than $3 + 2(p-1)/(2-p)$. Then we conclude that for $\lambda \geq 10^{d+1} 2^{jd}$, using the bound on $\sum \text{rad}(B_n)$ and the individual upper bounds on $\text{rad}(B_n)$, imply that
%
% 2^{jd(p-1)}
%
\begin{align*}
    &\Big\| \sum\nolimits_{a,b} \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0} \Big\|_{L^1(\text{Bad}_k^c)}\\
    &\quad\quad\quad \lesssim_X \sum_n 2^{k (d-1)} (2^j \text{rad}(B_n))^{d + 2 - M}\\
    &\quad\quad\quad \lesssim 2^{k(d-1)} A^{- \frac{M - d - 2}{d - 1}} A^{-1} \# \mathcal{E}_k \\
    &\quad\quad\quad \lesssim 2^{k (d-1)} A^{- \frac{M-3}{d-1}} \# \mathcal{E}_k\\
    &\quad\quad\quad \lesssim 2^{k(d-1)} \left( \log(\lambda / 2^{jd})^{\left( \frac{d-1}{2} \right)} (\lambda / 2^{jd})^{(2-p) \left( \frac{d - 1}{2} \right)} \right)^{- \frac{M-3}{d-1}} \# \mathcal{E}_k\\
    &\quad\quad\quad \lesssim 2^{jd(p-1)} \Big( 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{1-p}.
%    &\quad\quad\quad \lesssim 2^{j \left[\alpha(p) + d/p' \right]} ( \lambda / 2^{jd} )^{- (2 - p) \left( \frac{d-1}{2} \right) \left( \frac{M-2}{d-1} \right)} \left( 2^{k \left( \frac{d - 1}{2} \right)} \# \mathcal{E}_k \right)\\
%    &\quad\quad\quad \lesssim 2^{jd/p'} \left( 2^{k \left( \frac{d - 1}{2} \right)} \# \mathcal{E}_k \right)
\end{align*}
%
The last inequality again used the fact that $\log(x)^\delta x^{-\varepsilon} \lesssim 1$ for any $\delta,\varepsilon > 0$ and $x \geq 10^{d+1}$.
% j(d-1)
%
%     \left( A^{-1} \# \mathcal{E}_k \right) (A / 2^d)^{\frac{d+1-M}{d-1}}\\
%    &\quad\quad\quad \lesssim_n 2^{k \left( \frac{3d - 3}{2} \right)} A^{\frac{2 - M}{d - 1}} \# \mathcal{E}_k\\
%    &\quad\quad\quad \lesssim_n 2^{k \left( \frac{3d - 3}{2} \right)} \left( \lambda / 2^{jd} \right)^{\frac{(2-p)(2 - M)}{2}} \# \mathcal{E}_k\\
%    &\quad\quad\quad \lesssim 2^{jd(p-1)} 2^{k(d-1)} \Big( 2^{k \left( \frac{d-1}{2} \right)} \# \mathcal{E}_k \Big) \lambda^{1-p}
%
But this means that
%
\begin{align*}
    &\Big\| \sum\nolimits_k \sum\nolimits_{a,b} \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}} 2^{k \left( \frac{d-1}{2} \right)} 2^{-(a+b)} f_{x_0,t_0} \Big\|_{L^1(\text{Bad}^c)}\\
    &\quad\quad\quad\quad \lesssim \Big( 2^{jd(p-1)} \sum_k 2^{k(d-1)} \# \mathcal{E}_k \Big) \lambda^{1-p}.
\end{align*}
%
Applying Markov's inequality, this is enough to justify that
%
\begin{align} \label{LastMarkovRemainderBound}
\begin{split}
    &\bigg| \Big\{ x \in \text{Bad}^c: \Big|\sum\nolimits_{a,b} \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b} - \widehat{\mathcal{E}}_{k,a,b}} 2^{-(a+b)} f_{x_0,t_0}(x)\Big| \geq \lambda / 2 \Big\} \bigg|\\
    &\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad \lesssim 2^{jd(p-1)} \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-p}.
\end{split}
\end{align}
%
Putting \eqref{ChebyshevFirstBound}, \eqref{BadSet}, and \eqref{LastMarkovRemainderBound} together implies that for $\lambda \geq 2^{jd}$,
%
\begin{align*}
    &\bigg| \Big\{ x: \Big|\sum\nolimits_{a,b} \sum\nolimits_k \sum\nolimits_{(x_0,t_0) \in \mathcal{E}_{k,a,b}} 2^{-(a+b)} f_{x_0,t_0}(x)\Big| \geq \lambda \Big\} \bigg| \\
    &\quad\quad\quad \lesssim 2^{jd(p-1)} \left( \sum_k 2^{k(d-1)} \# \mathcal{E}_k \right) \lambda^{-p}
\end{align*}
%
This completes the proof of \eqref{FSumLPInfBound}, and thus the theorem.
\end{proof}

% The sum of S\!_{x_0,t_0}, where (x_0,t_0) range over some ball B_j
% has measure concentrated on a radius ~ 2^k / R annulus with thickness rad(B_j), a set with measure (2^k / R)^{d-1} rad(B_j).

%
% Picking A = (L / R^{d-1})^{ps_n}
% gives slightly too large a bound,
% by a factor log(L / R^{d-1})
%
% If we can replace ps_p by ps_p - epsilon
% we're probably good.
%
% Or even (L / R^{d-1})^{ps_p} log ( L / R^{d-1} )^{-O(1)}
%
% Then
%
% We're left with dealing with the concentrated case
% points are covered by balls B_1 ... B_N with radius at most 2^k / R
% and with sum rad(B_i) <= R^{-1} A^{-1} #E_k
%
% <= R^{-1} (L / R^{d-1})^{-(d-1)(1 - p/2)} log(L / R^{d-1})^{O(1)}
%
% The sum of S\!_{x_0,t_0}, where (x_0,t_0) range over some ball B_j
% has measure concentrated on a radius ~ 2^k / R annulus with thickness rad(B_j), a set with measure (2^k / R)^{d-1} rad(B_j).
%
% Summing over j, the total measure of these annulus are
%
% << (2^k / R)^{d-1} R^{-1} (L / R^{d-1} )^{-(d-1)(1 - p/2)} log(L / R^{d-1})^{O(1)}
% 2^{k(d-1)} R^{-d + (d-1)p} L^{-p} #(E_k)
%

% This is good provided that
% R^{d-2} L^{2p/(d-1) - 2} <= L^{-p} R^{(d-1)p - d}
% R^{(2-p)(d-1)} <= L^{2-p - 2p/(d-1)}
% R^{(2-p)(d-1)} <= L^{2 - p( (d+1)/(d-1) )}
% L >= R^{(d-1) [ (2-p)/(2 - p(d+1)/(d-1))]} = R^{(d-1) + eps_p}
% The right exponent exceeds d-1 in the range we are considering
% Shouldn't this be bad?

% s(lambda))^{2p/(d-1)} <= lambda^{2-p} R^{-(2-p)(d-1)}
% s(lambda) <= lambda^{ s_p } R^{ - (d-1)s_p } = ( lambda / R^{d-1} )^{s_p}
% p = 2 (d-1)/ (d+1)

% (2 - p)(d-1) / 2p > 1 in the range we are considering

% log_2(s(lambda)) s(lambda) <= lambda^{(2-p)(d-1)/2p} R^{[(d-1)^2(p-1) - d(d-1)]/2p}


% \log_2(\lambda) lambda^{(d+1)/(d-1)[p - 2(d-1)/(d+1)]} <= R^{2 + (d-1)p - 2d}
% if
% R^{(2-p)(d-1)} <= lambda^{2 - p(d+1)/(d-1)}
% which holds iff
% lambda >= R^{(2-p)(d-1)/[2 - p(d+1)/(d-1)]}
% L^{(2p)/(d-1) - 2 + p} <= R^{(d-1)p - d + 2 - d} 

% d > (p+2)/(2-p)
% 


\end{comment}








\section{Analysis of Regime II via Local Smoothing} \label{regime2finalsection}

In this section, we bound the operators $\{ T^{II} \}$, by a reduction to an endpoint local smoothing inequality, namely, the inequality that
%
\begin{equation} \label{thelocalsmoothinginequality}
    \| e^{2\pi i t P} f \|_{L^{p'}(X) L^{p'}_t(I_0)} \lesssim \| f \|_{L^{p'}_{s - 1/p'}}.
\end{equation}
%
This inequality is proved in Corollary 1.2 of \cite{LeeSeeger} for $1 < p < 2(d-1)/(d+1)$ for $P \in \COP{1}(X)$ satisfying the cosphere assumption of Theorem \ref{maintheorem}. The range of $p$ here is also precisely the range of $p$ in Theorem \ref{maintheorem}. Alternatively, Lemma \ref{LpBoundLemma} can be used to prove \eqref{thelocalsmoothinginequality} independently of \cite{LeeSeeger} in the same range by a generalization of the method of Section 10 of \cite{HeoandNazarovandSeeger}.

\begin{lemma} \label{LocalSmoothingLargeTimesTheorem}
    Using the notation of Proposition \ref{TjbLemma}, let
    %
    \[ T^{II} = \int b^{II}(t) (e^{2 \pi i t P} \circ Q_R)\; dt. \]
    %
    For $1 < p < 2 (d-1)/(d+1)$, we then have
    %
    \[ \| T^{II} u \|_{L^p(X)} \lesssim R^{s - 1/p'} \| b^{II} \|_{L^p(I_0)} \| u \|_{L^p(X)}. \]
\end{lemma}
\begin{proof}
    For each $R$, the \emph{class} of operators of the form $\{ T^{II} \}$ formed from a given function $b^{II}$ is closed under taking adjoints. Indeed, if $T^{II}$ is obtained from $b^{II}$, then $(T^{II})^*$ is obtained from the multiplier $\overline{b^{II}}$. Because of this self-adjointness, if we can prove that
    %
    \begin{equation}
        \| T^{II} u \|_{L^{p'}(X)} \lesssim R^{s - 1/p'} \| b^{II} \|_{L^p(I_0)} \| u \|_{L^{p'}(X)},
    \end{equation}
    %
    then we obtain the required result by duality. We apply this duality because it is easier to exploit local smoothing inequalities in $L^{p'}(X)$ since now $p' > 2$.

    Applying H\"{o}lder and Minkowski's inequalities, we find that
    %
    \begin{equation}
    \begin{split}
        \| T^{II}u \|_{L^{p'}(X)} &\leq \| b^{II} \|_{L^p(\RR)} \Big\| \Big( \int_{I_0} |e^{2 \pi i t P} (Q_R u)|^{p'} \Big)^{1/p'} \Big\|_{L^{p'}(X)}.
    \end{split}
    \end{equation}
    %
    Applying the endpoint local smoothing inequality \eqref{thelocalsmoothinginequality}, we conclude that
    %
    \begin{equation}
    \begin{split}
        \| T^{II} u \|_{L^{p'}(X)} &\lesssim \| b^{II} \|_{L^p(\RR)}  \| e^{2 \pi i P} (Q_R u) \|_{L^{p'}_t L^{p'}_x}\\
        &\lesssim  \| b^{II} \|_{L^p(\RR)}  \| Q_R u \|_{L^q_{s - 1/p'}(X)},
    \end{split}
    \end{equation}
    %
    The operator $L_R = R^{1/p' - s} \langle P \rangle^{s - 1/p'} Q_R$ can be written as $l_R(P)$, where $l_R(\lambda) = R^{1/p' - s} \langle \lambda \rangle^{s - 1/p'} q(\lambda/R)$. Since the functions $l_R$ are \emph{uniformly} symbols of order zero, i.e. for $R \geq 1$ we have uniform estimates $(\partial^\alpha l_R)(\lambda) \lesssim_\alpha \langle \lambda \rangle^{- \alpha}$, Corollary 4.3.2 of \cite{Sogge} implies that the operators $\{ L_R \}$ are uniformly bounded on $L^p(X)$. But this means that
    %
    \begin{equation}
        \| Q_R u \|_{L^{q}_{s - 1/p'}(X)} = R^{s - 1/p'} \| L_R u \|_{L^q(X)} \lesssim R^{s - 1/p'} \| u \|_{L^p(X)}.
    \end{equation}
    %
    Thus we conclude that
    %
    \begin{equation}
        \| T^{II}u \|_{L^{p'}(X)} \lesssim R^{s - 1/p'} \| b^{II} \|_{L^p(I_0)} \| u \|_{L^{p'}(X)},
    \end{equation}
    %
    which completes the proof.
\end{proof}

Combining Lemma \ref{regime1Lemma} and Lemma \ref{LocalSmoothingLargeTimesTheorem} completes the proof of Proposition \ref{TjbLemma}, and thus of inequality \eqref{dyadicMainReulst}. Since \eqref{TrivialLowFrequencyBound} was already proven as a consequence of Lemma \ref{lowjLemma}, this completes the proof of Theorem \ref{maintheorem}.

%Indeed, if we fix an arbitrary point $v_0 \in T_x^*M$, and consider the smallest closed ball $B \subset T_x^* M$ centered at $v_0$ and containing $S\!_x^*$, then the sphere $\partial B$ must share the same tangent plane as $S\!_x^*$ at some point. All principal curvatures of $\partial B$ are positive, and at this point all principal curvatures of $S\!_x^*$ must be greater than the principal curvatures of $\partial B$, since $S\!_x^*$ curves away faster than $\partial B$ in all directions. By continuity, we conclude that the principal curvatures are everywhere positive. 





\begin{comment}

\section{Necessary Conditions}

Let $m: [0,\infty) \to \CC$ be a function such that the spectral multiplier operators
%
\[ \{ m(\sqrt{-\Delta} / R) \} \]
%
are uniformly bounded on $L^p(S^d)$. Define $\psi: [0,\infty) \to [0,\infty)$ such that $\sqrt{-\Delta} = \psi(P)$ for an elliptic pseudodifferential operator $P$ commuting with $\sqrt{-\Delta}$, and with $\sigma(P) \subset \NN$. Define $m_R(\lambda) = m(\psi(\lambda)/R)$, so that 
%
\[ m(\sqrt{-\Delta} / R) = m_R(P). \]
%
If $\text{supp}(m) \subset [1/2,2]$, then $\text{supp}(m_R) \subset [R/4,4R]$ for suitably large $R$. If we define
%
\[ b_R(t) = \sum_{n = 0}^\infty m_R(n) \cos(2 \pi n t), \]
%
then we can write
%
\[ m_R(P) = 2 \int_0^{1/2} b_R(t) \cos(2 \pi P t)\; dt \]
%
Consider a normal coordinate system $\mathfrak{x}$ centered at a point $x_0 \in S^d$, and use it to define a family of bump functions $f_R: S^d \to \CC$ for $R \geq 1$ by setting $f_R = R^{d/p} f(R \mathfrak{x})$ for some fixed $f \in C_c^\infty(\RR^d)$ supported in a small neighbourhood of the origin. If we consider a partition of unity $\chi_0, \chi_1, \chi_2$ subordinate to the cover $[0,10/R)$, $(5/R, 1/2 - 5/R)$, $(1/2 - 10/R, 1/2]$, then we can write
%
\[ m_R(P) \{ f_R \} = 2(g_{R,0} + g_{R,1} + g_{R,2} + g_{R,\infty}) \]
%
where
%
\[ g_{R,j} = \int_0^{1/2} \chi_j(t) b_R(t) C_j(t) \{ f_R \}\; dt \]
%
and
%
\[ g_{R,\infty} = \int_0^{1/2} b_R(t) C_\infty(t) \{ f_R \}\; dt, \]
%
where $C_j(t)$ is a parametrix for $\cos(2 \pi P t)$, and $C_\infty(t)$ is an operator with a smooth kernel in $C^\infty([0,1/2] \times S^d \times S^d)$. Now applying Fourier series, we can write
%
\[ g_{R,\infty} = \sum_{n = 0}^\infty m_R(n) \widehat{C}_\infty(n) \{ f_R \}\; dt, \]
%
where $\widehat{C}_\infty(n)$ is rapidly decaying in $n$. But since $m_R(n)$ is supported on $[R/4,4R]$, we conclude that
%
\[ |\widehat{C}_\infty(n) \{ f_R \}| \lesssim_N R^{-N} |n|^{-10d}, \]
%
and thus
%
\[ \| g_{R,\infty} \|_{L^\infty(S^d)} \lesssim_N R^{-N} \| m \|_{L^\infty}\quad\text{for all $N \geq 0$}. \]
%
One can show (via a Fourier inversion, interpolation, and pseudodifferential operator argument) that for $x \in S^d$ with $d(x,x_0) \geq C_0 / R$,
%
\[ |g_{R,0}(x)| \lesssim_N \| m \|_{L^\infty} R^{d/p} |R d(x,x_0) |^{-d-N} \quad\text{for all $N \geq 0$}. \]
%
Similarily, if $x_0^* \in S^d$ is the antipode of $x_0$, then for $d(x,x_0^*) \geq C_0 / R$,
%
\[ |g_{R,2}(x)| \lesssim_N \| m \|_{L^\infty} R^{d/p} |R d(x,x_0^*) |^{-d-N} \quad\text{for all $N \geq 0$}. \]
%
If we let $\Omega = \{ x \in S^d: d(x,x_0) \geq C_0 / R\ \text{and}\ d(x,x_0^*) \geq C_0 / R \}$, then
%
\[ \| g_{R,0} \|_{L^p(\Omega)} + \| g_{R,2} \|_{L^p(\Omega)} \lesssim \| m \|_{L^\infty} R^{-d/p^*} \]
%
Now we introduce the Hadamard parametrix, writing
%
% \[ C_1(t,x,y) = A_d\; t \sum_{j = 0}^\infty \frac{( -1 )^j}{4^j \Gamma(j - \frac{d-1}{2})} W_j(x,y) ( d(x,y)^2 - t^2 )^{j - \frac{d+1}{2}} \]
\[ C_1(t,x,y) = t \int_0^\infty a(x,y,\tau) e^{i \tau ( d(x,y)^2 - t^2 )}\; d\tau, \]
%
where $a$ is a symbol of order $(d-1)/2$ in the $\tau$ variable, whose principal symbol is a power of the volume density on the manifold $M$. In particular, $a(x,y,\tau) > 0$ for sufficiently large $\tau$. We consider a partition of unity $\tilde{\chi}_0, \tilde{\chi}_1, \tilde{\chi}_2$ subordinate to $[0,1/5), (1/10, 10), (5,\infty)$ and use this parition to partition the regions of integration in the $\tau$ variable, writing $g_{R,1} = g_{R,1,0} + g_{R,1,1} + g_{R,1,2}$, where
%
\[ g_{R,1,j}(x) = \int \int a(x,y,\tau) \tilde{\chi}_j(\tau / R) b_R(t) t e^{i \tau ( d(x,y)^2 - t^2 ) } f_R(y)\; d\tau\; dt\; dy. \]
%
Integration by parts in the $t$ variable shows that for $j \in \{ 0, 2 \}$ $\| g_{R,1,j} \|_{L^\infty} \lesssim_N R^{-N} \| m \|_{L^\infty}$. Rescaling, writing $a_R(x,y,\tau) = R^{- \frac{d-1}{2}} a(x,y,R \tau) \tilde{\chi}_j(\tau)$ we can write
%
\begin{align*}
    g_{R,1,1}(x) &= R^{\frac{d+1}{2} + \frac{d}{p}} \iiint a_R(x,y,\tau) b_R(t) t e^{i R \tau ( d(x,y)^2 - t^2 )} f(Ry)\; d\tau\; dt\; dy.
%    &= R^{\frac{d+1}{2} + \frac{d}{p}} \iint (\mathcal{F}_\tau a_R)(x,y,R [ d(x,y)^2 - t^2 ]) b_R(t) t f(Ry)\; dt\; dy
\end{align*}
%
For our purposes (TODO: Justify Later) we may assume $d(x,y) \approx d(x,0) + y \cdot x / |x|$, and that $d(x,y)^2 \approx d(x,0)^2 + 2 d(x,0)  (y \cdot x / |x|)$. Thus
%
\[ g_{R,1,1}(x) \approx R^{\frac{d+1}{2} - \frac{d}{p'}} \iint a_R(x,\tau) b_R(t) t e^{i R \tau [d(x,0)^2 - t^2]}. \]
%
Thus
%
\[ g_{R,1,1}(x) \approx R^{\frac{d+1}{2} - \frac{d}{p'}} \int \widehat{a}_R \big(x, R[d(x,0)^2 - t^2] \big) b_R(t) t\; dt \]

\end{comment}